{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "40c4ff0240da4c819297cd36f3fbbe82": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c4da8d68af2c472ea3783a1329da8271",
              "IPY_MODEL_5a4f2457b5c6488faad8edb17076a720",
              "IPY_MODEL_0b4fec16ee514996aeeb8ece1f40a940"
            ],
            "layout": "IPY_MODEL_c8817827b02e415d8426320bf6c9d810"
          }
        },
        "c4da8d68af2c472ea3783a1329da8271": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_65d9ba835b9942d49750c1377c0fec38",
            "placeholder": "​",
            "style": "IPY_MODEL_38bb6d41e22a442ab1aca7606a7d7ac5",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "5a4f2457b5c6488faad8edb17076a720": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8ff8dcd68684435cbac70b86e4cf8425",
            "max": 48,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1c75cb159bfa485ebe07a7e849d508f1",
            "value": 48
          }
        },
        "0b4fec16ee514996aeeb8ece1f40a940": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_289b1c789b9143a7b0d0cb1503f2fca8",
            "placeholder": "​",
            "style": "IPY_MODEL_11437899c59e4c7784e5d0597daaa389",
            "value": " 48.0/48.0 [00:00&lt;00:00, 1.93kB/s]"
          }
        },
        "c8817827b02e415d8426320bf6c9d810": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "65d9ba835b9942d49750c1377c0fec38": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "38bb6d41e22a442ab1aca7606a7d7ac5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8ff8dcd68684435cbac70b86e4cf8425": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1c75cb159bfa485ebe07a7e849d508f1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "289b1c789b9143a7b0d0cb1503f2fca8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "11437899c59e4c7784e5d0597daaa389": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "de97ce72544542e292a4679717d891ea": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_cefc1d4e60134315a511b58a5dca9311",
              "IPY_MODEL_ba2b844283c44e51979a95b53d7c9bc6",
              "IPY_MODEL_a19eff763fc14fc890d90da582ad47b7"
            ],
            "layout": "IPY_MODEL_ee97b28bf4a64cc790ec13e4b6afef4e"
          }
        },
        "cefc1d4e60134315a511b58a5dca9311": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5ba15e7c9f4c4326a6d0d74422a8da3b",
            "placeholder": "​",
            "style": "IPY_MODEL_d5d0a3aa686c4616a18f659339a50acf",
            "value": "config.json: 100%"
          }
        },
        "ba2b844283c44e51979a95b53d7c9bc6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_24b913a23878433ca51c527974b30352",
            "max": 570,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_29b986af199e4eccaf4727d80678adda",
            "value": 570
          }
        },
        "a19eff763fc14fc890d90da582ad47b7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bd2e23feeff74ec5be8c2412f95ee5f5",
            "placeholder": "​",
            "style": "IPY_MODEL_4449b6faefef4980a464d2af94f8c677",
            "value": " 570/570 [00:00&lt;00:00, 33.2kB/s]"
          }
        },
        "ee97b28bf4a64cc790ec13e4b6afef4e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5ba15e7c9f4c4326a6d0d74422a8da3b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d5d0a3aa686c4616a18f659339a50acf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "24b913a23878433ca51c527974b30352": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "29b986af199e4eccaf4727d80678adda": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "bd2e23feeff74ec5be8c2412f95ee5f5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4449b6faefef4980a464d2af94f8c677": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2b056e39cb284308af5db3d03b175cab": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_247fdc3d8daf44a38f622cee33baf3d4",
              "IPY_MODEL_a654f6beb9d4407a8e6ad5a04a4a9f97",
              "IPY_MODEL_0221f4a1c91b4637a8e7383fb0d60251"
            ],
            "layout": "IPY_MODEL_93fd40309d6d483ca5b9c70619494fa9"
          }
        },
        "247fdc3d8daf44a38f622cee33baf3d4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_04781aa753af49bab21769037682e052",
            "placeholder": "​",
            "style": "IPY_MODEL_e7a23fd2ef934f98b6794432203e47cd",
            "value": "vocab.txt: 100%"
          }
        },
        "a654f6beb9d4407a8e6ad5a04a4a9f97": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_077c74fb2d19408686a70bbd5482d6b1",
            "max": 231508,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_54249bc9ae9247ca81579261c6a8d255",
            "value": 231508
          }
        },
        "0221f4a1c91b4637a8e7383fb0d60251": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bac9f49fbc6947b389ba4b54ec934a85",
            "placeholder": "​",
            "style": "IPY_MODEL_c431dbafcd5141cfad7120c5dc788502",
            "value": " 232k/232k [00:00&lt;00:00, 2.81MB/s]"
          }
        },
        "93fd40309d6d483ca5b9c70619494fa9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "04781aa753af49bab21769037682e052": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e7a23fd2ef934f98b6794432203e47cd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "077c74fb2d19408686a70bbd5482d6b1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "54249bc9ae9247ca81579261c6a8d255": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "bac9f49fbc6947b389ba4b54ec934a85": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c431dbafcd5141cfad7120c5dc788502": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1c0132d0960146d3a3916d049372da79": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_67da75eaf69a4379a296c72fd44aafc2",
              "IPY_MODEL_3cfd64a7b0754bff841ced26acc0035e",
              "IPY_MODEL_f2d943e48dd04d4391a9c39bef64d479"
            ],
            "layout": "IPY_MODEL_c0ba67cac8c94e94822569ed650c0476"
          }
        },
        "67da75eaf69a4379a296c72fd44aafc2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c258dcd55d5b40fa8d208236a42e3688",
            "placeholder": "​",
            "style": "IPY_MODEL_879f34fa64c0434b94fdd64714277506",
            "value": "tokenizer.json: 100%"
          }
        },
        "3cfd64a7b0754bff841ced26acc0035e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_08783f3908714f059c610b0a7f636cbd",
            "max": 466062,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_58e387ac534f489dbe083a2655ef408e",
            "value": 466062
          }
        },
        "f2d943e48dd04d4391a9c39bef64d479": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_15feaaa472b74c3b919ae599093381ab",
            "placeholder": "​",
            "style": "IPY_MODEL_3d1d17ed38c24aaf9095855f7df1573f",
            "value": " 466k/466k [00:00&lt;00:00, 2.37MB/s]"
          }
        },
        "c0ba67cac8c94e94822569ed650c0476": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c258dcd55d5b40fa8d208236a42e3688": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "879f34fa64c0434b94fdd64714277506": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "08783f3908714f059c610b0a7f636cbd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "58e387ac534f489dbe083a2655ef408e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "15feaaa472b74c3b919ae599093381ab": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3d1d17ed38c24aaf9095855f7df1573f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Homework 1: Text Classification\n",
        "## Due Date: Mon, Sep 16, 2024, 11:59 PM EST\n",
        "- **Overview**: For this assignment, we’ll be building a text classifier. The goal of our text classifer will be to distinguish between words that are simple and words that are complex. Example simple words are `heard`, `sat`, and `town`, and example complex words are `abdicate`, `detained`, and `vintners`. Distinguishing between simple and complex words is the first step in a larger NLP task called text simplification, which aims to replace complex words with simpler synonyms. Text simplification is potentially useful for re-writing texts so that they can be more easily understood by younger readers, people learning English as a second language, or people with learning disabilities.\n",
        "\n",
        "- **Learning goals**:\n",
        "    - Understand an important class of NLP evaluation methods (precision, recall and F1), and implement them yourself.\n",
        "    - Employ common experimental design practices in NLP. Split the annotated data into training/development/test sets, implement simple baselines to determine how difficult the task is, and experiment with a range of features and models.\n",
        "    - Get an introduction to `sklearn`, an excellent machine learning Python package.\n",
        "\n",
        "- **Data**: We will provide you with training and development data that has been manually labeled. We will also give you a test set without labels. You will build a classifier to predict the labels on our test set. You can upload your classifier’s predictions to Gradescope. We will score its predictions and maintain a leaderboard showing whose classifier has the best performance.\n",
        "\n",
        "## Recommended Readings\n",
        "- [Naive Bayes Classification and Sentiment](https://web.stanford.edu/~jurafsky/slp3/4.pdf) Dan Jurafsky and James H. Martin. Speech and Language Processing (3rd edition draft).\n",
        "- [Logistic Regression](https://web.stanford.edu/~jurafsky/slp3/5.pdf) Dan Jurafsky and James H. Martin. Speech and Language Processing (3rd edition draft) .\n",
        "- [Problems in Current Text Simplification Research: New Data Can Help](http://www.cis.upenn.edu/~ccb/publications/new-data-for-text-simplification.pdf) Wei Xu, Chris Callison-Burch, and Courtney Napoles. TACL 2015.\n",
        "- [Comparison of Techniques to Automatically Identify Complex Words](http://aclweb.org/anthology/P/P13/P13-3015.pdf) Matthew Shardlow. ACL 2013.\n",
        "- [SemEval 2016 Task 11: Complex Word Identification](https://www.researchgate.net/profile/Gustavo_Paetzold/publication/305334627_SemEval_2016_Task_11_Complex_Word_Identification/links/57bab70a08ae14f440bd9722/SemEval-2016-Task-11-Complex-Word-Identification.pdf) Gustavo Paetzold and Lucia Specia. ACL 2016."
      ],
      "metadata": {
        "id": "QUzMpi3XpWYg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setup 1: PennGrader Setup"
      ],
      "metadata": {
        "collapsed": false,
        "id": "HjSvDozeJomQ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "uCEi3Stv9lun",
        "ExecuteTime": {
          "end_time": "2024-09-14T03:24:09.617997Z",
          "start_time": "2024-09-14T03:24:06.419222Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7b6f542d-cc02-4a0d-98d7-bd38a7ea649b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting penngrader-client\n",
            "  Downloading penngrader_client-0.5.2-py3-none-any.whl.metadata (15 kB)\n",
            "Collecting dill\n",
            "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from penngrader-client) (6.0.2)\n",
            "Downloading penngrader_client-0.5.2-py3-none-any.whl (10 kB)\n",
            "Downloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: dill, penngrader-client\n",
            "Successfully installed dill-0.3.8 penngrader-client-0.5.2\n"
          ]
        }
      ],
      "source": [
        "## DO NOT CHANGE ANYTHING, JUST RUN\n",
        "# %%capture\n",
        "!pip install penngrader-client dill"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile notebook-config.yaml\n",
        "\n",
        "grader_api_url: 'https://23whrwph9h.execute-api.us-east-1.amazonaws.com/default/Grader23'\n",
        "grader_api_key: 'flfkE736fA6Z8GxMDJe2q8Kfk8UDqjsG3GVqOFOa'\n"
      ],
      "metadata": {
        "id": "AsOtK_aN65OD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7d124897-0b28-49b8-f503-2f0c9a737671",
        "ExecuteTime": {
          "end_time": "2024-09-14T03:24:10.844092Z",
          "start_time": "2024-09-14T03:24:10.839351Z"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing notebook-config.yaml\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cat notebook-config.yaml"
      ],
      "metadata": {
        "id": "A54Qn8Fc65rr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "41f0e3db-8d92-41a8-ff30-639c7fc8cbb2",
        "ExecuteTime": {
          "end_time": "2024-09-14T03:24:12.060265Z",
          "start_time": "2024-09-14T03:24:11.917317Z"
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "grader_api_url: 'https://23whrwph9h.execute-api.us-east-1.amazonaws.com/default/Grader23'\n",
            "grader_api_key: 'flfkE736fA6Z8GxMDJe2q8Kfk8UDqjsG3GVqOFOa'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from penngrader.grader import *\n",
        "\n",
        "## TODO - Start\n",
        "STUDENT_ID = 72377337 # YOUR PENN-ID GOES HERE AS AN INTEGER#\n",
        "## TODO - End\n",
        "\n",
        "SECRET = STUDENT_ID\n",
        "grader = PennGrader('notebook-config.yaml', 'cis5300_fa2024_HW1', STUDENT_ID, SECRET)"
      ],
      "metadata": {
        "id": "pqLZxuPW65o0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9c02a87a-7235-4f51-f1b6-21b7fc660b37",
        "ExecuteTime": {
          "end_time": "2024-09-14T03:24:13.126725Z",
          "start_time": "2024-09-14T03:24:13.061902Z"
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PennGrader initialized with Student ID: 72377337\n",
            "\n",
            "Make sure this correct or we will not be able to store your grade\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def reload_grader():\n",
        "    grader = PennGrader('notebook-config.yaml', 'cis5300_fa2024_HW1', STUDENT_ID, SECRET)\n",
        "    return grader"
      ],
      "metadata": {
        "id": "e8Oo9CBh65mO",
        "ExecuteTime": {
          "end_time": "2024-09-14T03:24:14.013449Z",
          "start_time": "2024-09-14T03:24:14.000955Z"
        }
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# check if the PennGrader is set up correctly\n",
        "# do not change this cell, see if you get 4/4 (Mark gives 2/4, showing the grading is working but that you haven't changed the info yet)!\n",
        "name_str = 'Yuanzhe Liu'\n",
        "grader.grade(test_case_id = 'name_test', answer = name_str)"
      ],
      "metadata": {
        "id": "XiuH5IC47AKJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e7d6414a-8571-460a-88ec-7e90311d9a71",
        "ExecuteTime": {
          "end_time": "2024-09-14T03:24:15.020113Z",
          "start_time": "2024-09-14T03:24:14.745989Z"
        }
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Correct! You earned 4/4 points. You are a star!\n",
            "\n",
            "Your submission has been successfully recorded in the gradebook.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wHeB9GLB-PO1"
      },
      "source": [
        "## Setup 2: Dataset / Packages\n",
        "- **Run the following cells without changing anything!**\n",
        "- [Loading dataset from huggingface](https://huggingface.co/docs/datasets/v1.8.0/loading_datasets.html#from-local-files)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import defaultdict\n",
        "import gzip\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "import numpy as np\n",
        "from tqdm import tqdm"
      ],
      "metadata": {
        "id": "g2eaUdk__tUv",
        "ExecuteTime": {
          "end_time": "2024-09-14T03:24:17.904280Z",
          "start_time": "2024-09-14T03:24:17.042498Z"
        }
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "# data\n",
        "!gdown 1np28I4b1Q1K6K49oiVx3hqEoh-KMbSml #dev https://drive.google.com/file/d/1np28I4b1Q1K6K49oiVx3hqEoh-KMbSml/view?usp=drive_link\n",
        "!gdown 1qu6CELzKzRM2x6qvyuaX5SWPIleHDfs6 # unlabeled https://drive.google.com/file/d/1qu6CELzKzRM2x6qvyuaX5SWPIleHDfs6/view?usp=drive_link\n",
        "!gdown 1JL7UK17loFTOf0WW5mLZgZMTWXZq3THW # train https://drive.google.com/file/d/1JL7UK17loFTOf0WW5mLZgZMTWXZq3THW/view?usp=drive_link\n",
        "!gdown 1ppyM-7kFyabNG8zOudsTuhWl-2j-zy5Z # https://drive.google.com/file/d/1ppyM-7kFyabNG8zOudsTuhWl-2j-zy5Z/view?usp=sharing\n",
        "!curl -L -o ngram_counts.txt.gz http://www.cis.upenn.edu/~cis5300/18sp/data/ngram_counts.txt.gz"
      ],
      "metadata": {
        "id": "rzmRKkBzqFq9",
        "ExecuteTime": {
          "end_time": "2024-09-14T03:25:10.223803Z",
          "start_time": "2024-09-14T03:24:18.877569Z"
        }
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!gdown 1rkYaFae_qJk1AlHORDLH3aPH47f9DA8s"
      ],
      "metadata": {
        "id": "rfCcEa82dwjv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0b757303-5719-4250-b41c-bf38b7f3bc55",
        "ExecuteTime": {
          "end_time": "2024-09-14T03:25:51.180251Z",
          "start_time": "2024-09-14T03:25:41.842888Z"
        }
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=1rkYaFae_qJk1AlHORDLH3aPH47f9DA8s\n",
            "From (redirected): https://drive.google.com/uc?id=1rkYaFae_qJk1AlHORDLH3aPH47f9DA8s&confirm=t&uuid=729e10ce-898c-4914-86ac-b1c9e03bc61e\n",
            "To: /content/ngram_counts.txt.gz\n",
            "100% 44.5M/44.5M [00:00<00:00, 111MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_file = \"complex_words_training.txt\"\n",
        "dev_file = \"complex_words_development.txt\"\n",
        "test_file = \"complex_words_test_unlabeled.txt\"\n",
        "mini_test_file = 'complex_words_test_mini.txt'"
      ],
      "metadata": {
        "id": "7Adfo88__puO",
        "ExecuteTime": {
          "end_time": "2024-09-14T03:25:53.386020Z",
          "start_time": "2024-09-14T03:25:53.378957Z"
        }
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "########## DO NOT CHANGE ##########\n",
        "## Loads in the words and labels of one of the datasets\n",
        "def load_labeled_file(data_file):\n",
        "    words = []\n",
        "    labels = []\n",
        "    with open(data_file, 'rt', encoding=\"utf8\") as f:\n",
        "        i = 0\n",
        "        for line in f:\n",
        "            if i > 0:\n",
        "                line_split = line[:-1].split(\"\\t\")\n",
        "                words.append(line_split[0].lower())\n",
        "                labels.append(int(line_split[1]))\n",
        "            i += 1\n",
        "    return words, labels\n",
        "\n",
        "def load_unlabeled_file(data_file):\n",
        "    words = []\n",
        "    # labels = []\n",
        "    with open(data_file, 'rt', encoding=\"utf8\") as f:\n",
        "        words = [line.strip() for line in f.readlines() if len(line.strip()) > 0]\n",
        "    return words\n",
        "\n",
        "def load_test_file(data_file):\n",
        "    words = []\n",
        "    with open(data_file, 'rt', encoding=\"utf8\") as f:\n",
        "        next(f) # skip first line (header)\n",
        "        words = [line.strip().split('\\t')[0] for line in f.readlines() if len(line.strip()) > 0]\n",
        "    return words\n",
        "\n",
        "## Loads Google NGram counts\n",
        "def load_ngram_counts(ngram_counts_file = 'ngram_counts.txt.gz'):\n",
        "    counts = defaultdict(int)\n",
        "    with gzip.open(ngram_counts_file, 'rt') as f:\n",
        "        for line in f:\n",
        "            token, count = line.strip().split('\\t')\n",
        "            if token[0].islower():\n",
        "                counts[token] = int(count)\n",
        "    return counts\n",
        "ngram_counts = load_ngram_counts()"
      ],
      "metadata": {
        "id": "sBvFx6rmqMU5",
        "ExecuteTime": {
          "end_time": "2024-09-14T03:26:07.892581Z",
          "start_time": "2024-09-14T03:25:54.526744Z"
        }
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### About the data\n",
        "- `train_data`, `dev_data`: these are words with labels, provided for you to train and evaluate your models.\n",
        "- `mini_test_words`: this is a subset (50) of the unseen test dataset, we will provide test the **basic functionality** of your models based on the performance on this mini testset (PennGrader tests). **This would only be a basic sanity check of your implementation. The final grade would be based on the PennGrader Grades and manual grading on your implementation**\n",
        "- `test_words`: this is the full, unlabelled test set. You are expected to submit the prediction of these words at the end of the assignment."
      ],
      "metadata": {
        "id": "e-cTPv6O5JHn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "########## DO NOT CHANGE ##########\n",
        "train_data = load_labeled_file(train_file)\n",
        "dev_data = load_labeled_file(dev_file)\n",
        "mini_test_words = load_unlabeled_file(mini_test_file)\n",
        "test_words = load_test_file(test_file)\n",
        "\n",
        "# you can take a look at this mini-dev data by uncommenting this line\n",
        "dev_words, dev_labels = dev_data\n",
        "dev_words[:5] # some examples of this dev dataset"
      ],
      "metadata": {
        "id": "lM2zO3eB5I3U",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "90db310c-9c86-4815-89a1-9f913b39b278",
        "ExecuteTime": {
          "end_time": "2024-09-14T03:26:13.244884Z",
          "start_time": "2024-09-14T03:26:13.160681Z"
        }
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['hammer', 'renewable', 'showings', 'academy', 'continues']"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mini_test_words[:5]"
      ],
      "metadata": {
        "id": "spBhnflE5I0_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8f406559-e14c-43d1-b049-8362e7045536",
        "ExecuteTime": {
          "end_time": "2024-09-14T03:26:15.827037Z",
          "start_time": "2024-09-14T03:26:15.810776Z"
        }
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['threads', 'reinforce', 'letters', 'pioneered', 'closer']"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Section 1. Implement the Evaluation Metrics\n",
        "- You might find this [Wikipedia Page](https://en.wikipedia.org/wiki/Precision_and_recall) useful.\n",
        "- **Problem 1.1** Predicion, Recall, F1 Score"
      ],
      "metadata": {
        "id": "QxKLifghqGI1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Input: y_pred, a list of length n with the predicted labels,\n",
        "## y_true, a list of length n with the true labels\n",
        "\n",
        "## Calculates the precision of the predicted labels\n",
        "def get_precision(y_true, y_pred):\n",
        "    true_positive = len([1 for true, pred in zip(y_true, y_pred) if true == 1 and pred == 1])\n",
        "    false_positive = len([1 for true, pred in zip(y_true, y_pred) if true == 0 and pred == 1])\n",
        "    precision = true_positive / (true_positive + false_positive) if (true_positive + false_positive) != 0 else 0\n",
        "    return precision\n",
        "\n",
        "## Calculates the recall of the predicted labels\n",
        "def get_recall(y_true, y_pred):\n",
        "    true_positive = len([1 for true, pred in zip(y_true, y_pred) if true == 1 and pred == 1])\n",
        "    false_negative = len([1 for true, pred in zip(y_true, y_pred) if true == 1 and pred == 0])\n",
        "    recall = true_positive / (true_positive + false_negative) if (true_positive + false_negative) != 0 else 0\n",
        "    return recall\n",
        "\n",
        "## Calculates the f-score of the predicted labels\n",
        "def get_fscore(y_true, y_pred):\n",
        "    precision = get_precision(y_true, y_pred)\n",
        "    recall = get_recall(y_true, y_pred)\n",
        "    fscore = (2 * precision * recall) / (precision + recall) if (precision + recall) != 0 else 0\n",
        "    return fscore"
      ],
      "metadata": {
        "id": "XTSjcJi4qL9H",
        "ExecuteTime": {
          "end_time": "2024-09-14T04:27:43.210380Z",
          "start_time": "2024-09-14T04:27:43.186915Z"
        }
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#DO NOT CHANGE!\n",
        "\n",
        "from dill.source import getsource\n",
        "grader.grade(test_case_id = 'test_q11_eval_funcs', answer = (getsource(get_precision), getsource(get_recall), getsource(get_fscore)))"
      ],
      "metadata": {
        "id": "8IxXaxPwbMmQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7078b476-2498-422e-c6ca-56d4264cd583",
        "ExecuteTime": {
          "end_time": "2024-09-14T04:27:46.319839Z",
          "start_time": "2024-09-14T04:27:46.006864Z"
        }
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Correct! You earned 12/12 points. You are a star!\n",
            "\n",
            "Your submission has been successfully recorded in the gradebook.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Section 2. Baselines"
      ],
      "metadata": {
        "id": "NPWqpba5qMkS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.1 Implement a majority class baseline\n",
        "You should start by implementing simple baselines as classifiers. Your first baseline is a **majority class baseline** which is one of the most simple classifier. You should complete the function `all_complex(words)`, which takes in a list of words, and returns out the predictions.\n"
      ],
      "metadata": {
        "id": "Ce_lQ23GrM04"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- **Problem 2.1:** Implement `all_complex()` that always predicts the majority class of the data (i.e. predicting every word as complex)"
      ],
      "metadata": {
        "id": "ZSscYsHl9Hrz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Labels every word complex\n",
        "def all_complex(words):\n",
        "    ## YOUR CODE HERE...\n",
        "    y_pred = [1] * len(words)\n",
        "    return y_pred"
      ],
      "metadata": {
        "id": "PadhojvR81W2",
        "ExecuteTime": {
          "end_time": "2024-09-14T04:27:49.536527Z",
          "start_time": "2024-09-14T04:27:49.531206Z"
        }
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- **Answer 2.1:** Please report the precision, recall, and f-score on both the training data and the development data.\n",
        "    - Training: Precision: 0.43275; Recall: 1.0; F-score: 0.604083057058105\n",
        "    - Development: Precision: 0.418; Recall: 1.0; F-score: 0.5895627644569816\n"
      ],
      "metadata": {
        "id": "QTUh940XEA8W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "words, labels = train_data\n",
        "t_pred = all_complex(words)\n",
        "precision = get_precision(labels, t_pred)\n",
        "recall = get_recall(labels, t_pred)\n",
        "fscore = get_fscore(labels, t_pred)\n",
        "print('Training Data')\n",
        "print(f\"Precision: {precision}\")\n",
        "print(f\"Recall: {recall}\")\n",
        "print(f\"F-score: {fscore}\")\n",
        "\n",
        "words, labels = dev_data\n",
        "d_pred = all_complex(words)\n",
        "precision = get_precision(labels, d_pred)\n",
        "recall = get_recall(labels, d_pred)\n",
        "fscore = get_fscore(labels, d_pred)\n",
        "print('\\nDevelopment Data')\n",
        "print(f\"Precision: {precision}\")\n",
        "print(f\"Recall: {recall}\")\n",
        "print(f\"F-score: {fscore}\")"
      ],
      "metadata": {
        "id": "DLTmB2aw0fgC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "668963a7-bc1e-4587-dec6-ea77415366e5",
        "ExecuteTime": {
          "end_time": "2024-09-14T04:27:52.809975Z",
          "start_time": "2024-09-14T04:27:52.772827Z"
        }
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Data\n",
            "Precision: 0.43275\n",
            "Recall: 1.0\n",
            "F-score: 0.604083057058105\n",
            "\n",
            "Development Data\n",
            "Precision: 0.418\n",
            "Recall: 1.0\n",
            "F-score: 0.5895627644569816\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# PennGrader - DO NOT CHANGE\n",
        "all_complex_pred = all_complex(mini_test_words)\n",
        "grader.grade(test_case_id = 'test_baseline_q21', answer = all_complex_pred)"
      ],
      "metadata": {
        "id": "lL_sMcF0RBfm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d32cdf99-2458-45e4-b569-44dadc1561b1",
        "ExecuteTime": {
          "end_time": "2024-09-14T04:27:58.710860Z",
          "start_time": "2024-09-14T04:27:58.491628Z"
        }
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Correct! You earned 3/3 points. You are a star!\n",
            "\n",
            "Your submission has been successfully recorded in the gradebook.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.2 Word length baseline\n",
        "For our next baseline, we will use a slightly complex baseline, the length of each word to predict its complexity.\n",
        "\n",
        "For the word length baseline, you should try setting various thresholds for word length to classify them as simple or otherwise. For example, you might set a threshold of 9, meaning that any words with less than 9 characters will be labeled simple, and any words with 9 characters or more will be labeled complex. Once you find the best threshold using the training data, use this same threshold for the development data as well.\n",
        "\n",
        "You will be filling in the function `word_length_threshold(train_data, dev_data)`. This function takes in both the training and development datasets, finds the best threshold on word length and returns out the predictions on development data for your best threshold.\n",
        "\n",
        "Usually, Precision and Recall are inversely related and while building binary-classification systems we try to find a good balance between them (by maximizing f-score, for example). It is often useful to plot the Precision-Recall curve for various settings of the classifier to gauge its performance and compare it to other classifiers. For example, for this baseline, a Precision-Recall curve can be plotted by plotting the Precision (on the y-axis) and Recall (on the X-axis) for different values of word-length threshold."
      ],
      "metadata": {
        "id": "CjVszF6NrOjr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- **Problem 2.2:** Implement `word_length_threshold()` that finds the best word length threshold and makes predictions on the development (or testing) data."
      ],
      "metadata": {
        "id": "AIDngmGzQSOV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### 2.2: Word length thresholding\n",
        "## Makes feature matrix for word_length_threshold\n",
        "def length_threshold_feature(words, threshold):\n",
        "    # return predictions based on the threshold\n",
        "    predictions = []\n",
        "    for word in words:\n",
        "      if len(word) < threshold:\n",
        "        predictions.append(0)\n",
        "      else:\n",
        "        predictions.append(1)\n",
        "    return predictions\n",
        "\n",
        "## Finds the best length threshold by f-score, and uses this threshold to\n",
        "## classify the training and development set\n",
        "def word_length_threshold(train_data, dev_data):\n",
        "    twords, tlabels = train_data\n",
        "    thresholds = range(max(len(word) for word in twords) + 1)\n",
        "    best_threshold = 0\n",
        "    cur_fscore = 0\n",
        "    for threshold in thresholds:\n",
        "      t_pred = length_threshold_feature(twords, threshold)\n",
        "      f1 = get_fscore(tlabels, t_pred)\n",
        "      if f1 > cur_fscore:\n",
        "        cur_fscore = f1\n",
        "        best_threshold = threshold\n",
        "    print(best_threshold)\n",
        "    # development dataset\n",
        "    dev_pred = length_threshold_feature(dev_data, best_threshold)\n",
        "    return dev_pred"
      ],
      "metadata": {
        "id": "ilbOj1BckJ8L",
        "ExecuteTime": {
          "end_time": "2024-09-14T05:14:27.797209Z",
          "start_time": "2024-09-14T05:14:27.766411Z"
        }
      },
      "execution_count": 92,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- **Answer 2.2:** Please report the precision, recall, and f-score on both the training data and the development data.\n",
        "    - Range of thresholds: The range of thresholds is [1,20], the best thresholds is 7\n",
        "    - Training: Precision: 0.6007401315789473; Recall: 0.8440207972270364; F1 Score: 0.7018976699495555\n",
        "    - Development: Precision: 0.6053511705685619; Recall: 0.8660287081339713; F1 Score: 0.7125984251968505\n",
        "    - Precision-recall Curve **[Plot below]**\n",
        "        - For plotting, [matplotlib](https://matplotlib.org/) is a useful python library\n"
      ],
      "metadata": {
        "id": "x4-j-HuIEnvy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Training Data\n",
        "twords, tlabels = train_data\n",
        "y_pred = word_length_threshold(train_data, twords)\n",
        "tprecision = get_precision(tlabels, y_pred)\n",
        "trecall = get_recall(tlabels, y_pred)\n",
        "tfscore = get_fscore(tlabels, y_pred)\n",
        "print('Training Data')\n",
        "print(f\"Precision: {tprecision}\")\n",
        "print(f\"Recall: {trecall}\")\n",
        "print(f\"F1 Score: {tfscore}\")\n",
        "\n",
        "# Development Data\n",
        "dwords, dlabels = dev_data\n",
        "d_pred = word_length_threshold(train_data, dwords)\n",
        "dprecision = get_precision(dlabels, d_pred)\n",
        "drecall = get_recall(dlabels, d_pred)\n",
        "dfscore = get_fscore(dlabels, d_pred)\n",
        "# Report the precision, recall, and f-score on the development data\n",
        "print('\\nDevelopment Data')\n",
        "print(f\"Precision: {dprecision}\")\n",
        "print(f\"Recall: {drecall}\")\n",
        "print(f\"F1 Score: {dfscore}\")"
      ],
      "metadata": {
        "id": "lHbIK7B4_wat",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3b3235e2-fa4d-4503-bcd6-78430ceb18ec",
        "ExecuteTime": {
          "end_time": "2024-09-14T05:14:30.401993Z",
          "start_time": "2024-09-14T05:14:30.330734Z"
        }
      },
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "7\n",
            "Training Data\n",
            "Precision: 0.6007401315789473\n",
            "Recall: 0.8440207972270364\n",
            "F1 Score: 0.7018976699495555\n",
            "7\n",
            "\n",
            "Development Data\n",
            "Precision: 0.6053511705685619\n",
            "Recall: 0.8660287081339713\n",
            "F1 Score: 0.7125984251968505\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Training ～ precision-recall\n",
        "twords, tlabels = train_data\n",
        "thresholds = range(20)\n",
        "train_precisions = []\n",
        "train_recalls = []\n",
        "for threshold in thresholds:\n",
        "    t_pred = length_threshold_feature(twords, threshold)\n",
        "    train_precisions.append(get_precision(tlabels, t_pred))\n",
        "    train_recalls.append(get_recall(tlabels, t_pred))\n",
        "\n",
        "# Development ～ precision-recall\n",
        "dwords, dlabels = dev_data\n",
        "dev_precisions = []\n",
        "dev_recalls = []\n",
        "for threshold in thresholds:\n",
        "    d_pred = length_threshold_feature(dwords, threshold)\n",
        "    dev_precisions.append(get_precision(dlabels, d_pred))\n",
        "    dev_recalls.append(get_recall(dlabels, d_pred))\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(train_recalls, train_precisions, marker='o', label='Training', color='blue')  # Training data in blue\n",
        "plt.plot(dev_recalls, dev_precisions, marker='s', label='Development', color='orange')  # Dev data in orange\n",
        "plt.title('Precision-Recall Curve')\n",
        "plt.xlabel('Recall')\n",
        "plt.ylabel('Precision')\n",
        "plt.ylim(-0.05, 1.05)\n",
        "plt.xlim(-0.05, 1.05)\n",
        "plt.grid(True)\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-09-14T04:52:12.230168Z",
          "start_time": "2024-09-14T04:52:11.652372Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 564
        },
        "id": "E19FcfaPJomU",
        "outputId": "f091cb25-7319-4ebb-a7e2-830117f1c1a8"
      },
      "execution_count": 95
    },
    {
      "cell_type": "code",
      "source": [
        "# PennGrader - DO NOT CHANGE\n",
        "word_length_pred = word_length_threshold(train_data, mini_test_words)\n",
        "grader.grade(test_case_id = 'test_baseline_q22', answer = word_length_pred)"
      ],
      "metadata": {
        "id": "MQuSkuYc8TeJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dd4a5a1b-0f91-4914-e050-a133bec5b0dd",
        "ExecuteTime": {
          "end_time": "2024-09-14T04:52:14.614152Z",
          "start_time": "2024-09-14T04:52:14.331100Z"
        }
      },
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "7\n",
            "Correct! You earned 3/3 points. You are a star!\n",
            "\n",
            "Your submission has been successfully recorded in the gradebook.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.3 Word frequency baseline\n"
      ],
      "metadata": {
        "id": "_6m7o8VwrQ4x"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Our final baseline is a classifier similar to the last one, but thresholds on word frequency instead of length. We have provided Google NGram frequencies in the text file ngram_counts.txt, along with the helper function `load_ngram_counts(ngram_counts_file)` to load them into Python as a dictionary.\n",
        "\n",
        "You will be filling in the function `word_frequency_threshold(train_data, dev_data, ngram_counts)`, where `ngram_counts` is the dictionary of word frequencies. This function again finds the best threshold and returns predictions on the development data.\n",
        "\n",
        "Please again report the precision, recall, and f-score on the training and development data individually, along with the range of thresholds you tried, and the best threshold to be graded. Similar to the previous baseline, plot the Precision-Recall curve for range of thresholds you tried. Compared with word length baseline, which classifier looks better on average?\n",
        "\n",
        "**Note: Due to its size, loading the ngram counts into Python takes around 20 seconds, and finding the correct threshold may take a few minutes to run.**"
      ],
      "metadata": {
        "id": "Bm3Lh9kvFaF5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- **Problem 2.3:** Implement `word_frequency_threshold()` that finds the best word frequency threshold and makes predictions on the development (or testing) data."
      ],
      "metadata": {
        "id": "JnceCMcoQuRg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Make feature matrix for word_frequency_threshold\n",
        "def frequency_threshold_feature(words, threshold, ngram_counts):\n",
        "    # return predictions based on the threshold\n",
        "    predictions = []\n",
        "    for word in words:\n",
        "      if ngram_counts[word] < threshold:\n",
        "        predictions.append(1)\n",
        "      else:\n",
        "        predictions.append(0)\n",
        "    return predictions\n",
        "\n",
        "def word_frequency_threshold(train_data, dev_data, ngram_counts):\n",
        "    twords, tlabels = train_data\n",
        "    MIN = min(ngram_counts[word] for word in twords)\n",
        "    MAX = max(ngram_counts[word] for word in twords)\n",
        "    thresholds = range(1000000, 30000000, 100000)\n",
        "    best_threshold = 0\n",
        "    cur_fscore = 0\n",
        "    for threshold in thresholds:\n",
        "        t_pred = frequency_threshold_feature(twords, threshold, ngram_counts)\n",
        "        f1 = get_fscore(tlabels, t_pred)\n",
        "        if f1 > cur_fscore:\n",
        "            cur_fscore = f1\n",
        "            best_threshold = threshold\n",
        "    print(best_threshold)\n",
        "    # development dataset\n",
        "    d_words = dev_data # 这里 dev_data 仅为d_words\n",
        "    dev_pred = frequency_threshold_feature(dev_data, best_threshold, ngram_counts)\n",
        "    return dev_pred"
      ],
      "metadata": {
        "id": "Mnkit06ncN07",
        "ExecuteTime": {
          "end_time": "2024-09-14T05:13:19.359674Z",
          "start_time": "2024-09-14T05:13:19.335420Z"
        }
      },
      "execution_count": 97,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- **Answer 2.3:** Please report the precision, recall, and f-score on both the training data and the development data.\n",
        "    - Range of thresholds: The range of thresholds used is from 1000000 to 30000000 with increments of 100000, and the best thresholds is 19900000.\n",
        "    - Training: Precision: 0.5657051282051282; Recall: 0.8157134604274986; F1 Score: 0.6680861130825645\n",
        "    - Development: Precision: 0.556782334384858; Recall: 0.8444976076555024; F1 Score: 0.6711026615969581\n",
        "    - Precision-recall Curve **[Plot below]**\n",
        "        - For plotting, [matplotlib](https://matplotlib.org/) is a useful python library"
      ],
      "metadata": {
        "id": "Rw-WAjxIFiiI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Training Data\n",
        "twords, tlabels = train_data\n",
        "t_pred = word_frequency_threshold(train_data, twords, ngram_counts)\n",
        "tprecision = get_precision(tlabels, t_pred)\n",
        "trecall = get_recall(tlabels, t_pred)\n",
        "tfscore = get_fscore(tlabels, t_pred)\n",
        "print('Training Data')\n",
        "print(f\"Precision: {tprecision}\")\n",
        "print(f\"Recall: {trecall}\")\n",
        "print(f\"F1 Score: {tfscore}\")\n",
        "\n",
        "# Development Data\n",
        "dwords, dlabels = dev_data\n",
        "d_pred = word_frequency_threshold(train_data, dwords, ngram_counts)\n",
        "dprecision = get_precision(dlabels, d_pred)\n",
        "drecall = get_recall(dlabels, d_pred)\n",
        "dfscore = get_fscore(dlabels, d_pred)\n",
        "# Report the precision, recall, and f-score on the development data\n",
        "print('\\nDevelopment Data')\n",
        "print(f\"Precision: {dprecision}\")\n",
        "print(f\"Recall: {drecall}\")\n",
        "print(f\"F1 Score: {dfscore}\")"
      ],
      "metadata": {
        "id": "USVhRHQO_uEn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d2406e81-778e-4fce-d0fb-56fb4af7e44e",
        "ExecuteTime": {
          "end_time": "2024-09-14T05:13:25.559609Z",
          "start_time": "2024-09-14T05:13:22.486868Z"
        }
      },
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "19900000\n",
            "Training Data\n",
            "Precision: 0.5657051282051282\n",
            "Recall: 0.8157134604274986\n",
            "F1 Score: 0.6680861130825645\n",
            "19900000\n",
            "\n",
            "Development Data\n",
            "Precision: 0.556782334384858\n",
            "Recall: 0.8444976076555024\n",
            "F1 Score: 0.6711026615969581\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## TODO\n",
        "# Training ～ precision-recall\n",
        "twords, tlabels = train_data\n",
        "thresholds = range(1000000, 30000000, 100000)\n",
        "train_precisions = []\n",
        "train_recalls = []\n",
        "for threshold in thresholds:\n",
        "  t_pred = frequency_threshold_feature(twords, threshold, ngram_counts)\n",
        "  train_precisions.append(get_precision(tlabels, t_pred))\n",
        "  train_recalls.append(get_recall(tlabels, t_pred))\n",
        "\n",
        "# Development ～ precision-recall\n",
        "dwords, dlabels = dev_data\n",
        "dev_precisions = []\n",
        "dev_recalls = []\n",
        "for threshold in thresholds:\n",
        "    d_pred = frequency_threshold_feature(dwords, threshold, ngram_counts)\n",
        "    dev_precisions.append(get_precision(dlabels, d_pred))\n",
        "    dev_recalls.append(get_recall(dlabels, d_pred))\n",
        "\n",
        "# precision-recall curve\n",
        "plt.plot(train_recalls, train_precisions, label='Training', color='blue')  # Training data in blue\n",
        "plt.plot(dev_recalls, dev_precisions, label='Development', color='orange')  # Dev data in orange\n",
        "plt.title('Precision-Recall Curve')\n",
        "plt.xlabel('Recall')\n",
        "plt.ylabel('Precision')\n",
        "plt.grid(True)\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "M4Kn7AwbX6WT",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "outputId": "02413238-06f9-49c9-9e34-e0d6f34e7520",
        "ExecuteTime": {
          "end_time": "2024-09-14T05:15:03.192878Z",
          "start_time": "2024-09-14T05:15:00.898717Z"
        }
      },
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# PennGrader - DO NOT CHANGE\n",
        "word_freq_pred = word_frequency_threshold(train_data, mini_test_words, ngram_counts)\n",
        "grader.grade(test_case_id = 'test_baseline_q23', answer = word_freq_pred)"
      ],
      "metadata": {
        "id": "Opp9TploM5N8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8e43b0f7-1784-4001-b244-712c680106b5",
        "ExecuteTime": {
          "end_time": "2024-09-14T05:15:13.905158Z",
          "start_time": "2024-09-14T05:15:10.392198Z"
        }
      },
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "19900000\n",
            "Correct! You earned 3/3 points. You are a star!\n",
            "\n",
            "Your submission has been successfully recorded in the gradebook.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Section 3. Classifiers"
      ],
      "metadata": {
        "id": "vL8m-NpOqTDG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.1 Naive Bayes classification\n"
      ],
      "metadata": {
        "id": "QCeaRTgprTWe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, let’s move on to actual machine learning classifiers! For our first classifier, you will use the built-in [Naive Bayes model from sklearn](https://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.GaussianNB.html), to train a classifier. You should refer to the online sklearn documentation when you are building your classifier.\n",
        "\n",
        "The first thing to note is that sklearn classifiers take in `numpy` arrays, rather than regular lists. You may use the [online numpy documentation](https://numpy.org/doc/stable/). To create a `numpy` list of length 5, you can use the following Python commands:\n",
        "\n",
        "```\n",
        "import numpy as np\n",
        "X = np.array([1,2,3,4,5])\n",
        "```\n",
        "\n",
        "\n",
        "To train a classifier, you need two numpy arrays: `X_train`, an `m` by `n` array, where `m` is the number of words in the dataset, and `n` is the number of features for each word; and `Y`, an array of length `m` for the labels of each of the words.\n",
        "\n",
        "**Before we start training models, we need to convert our texts/words into numpy arrays, i.e. making training/testing feature vectors.**"
      ],
      "metadata": {
        "id": "38p7gBNVFvoG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- **Problem 3.0**: Implementing `get_training_features()` and `get_test_features()` that convert train/test dataset to numpy arrays"
      ],
      "metadata": {
        "id": "nnO1kcuNENCe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "# run the following cell if you want to use count of syllabus as a feature\n",
        "!pip install syllables\n",
        "import syllables"
      ],
      "metadata": {
        "id": "9ILfZ05JGRtJ",
        "ExecuteTime": {
          "end_time": "2024-09-14T18:30:10.035049Z",
          "start_time": "2024-09-14T18:30:02.756351Z"
        }
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_training_features(train_data, ngram_counts):\n",
        "    words, y_true = train_data\n",
        "    features = []\n",
        "    for word in words:\n",
        "        length_feature = len(word) # word length feature\n",
        "        frequency_feature = ngram_counts.get(word, 0) # unigram frequency feature\n",
        "        syllable_feature = syllables.estimate(word)\n",
        "        features.append([length_feature, frequency_feature, syllable_feature])\n",
        "\n",
        "    X = np.asarray(features)\n",
        "    ## YOUR CODE HERE\n",
        "    # TODO: calculate the mean and std of the vectorized data (X)\n",
        "    means = np.mean(X, axis=0)\n",
        "    stds = np.std(X, axis=0)\n",
        "\n",
        "    stds[stds == 0] = 1\n",
        "\n",
        "    # TODO: calculate the scaled data, with the mean and std you just calculated\n",
        "    X_scaled = (X - means) / stds # 标准化/归一化\n",
        "\n",
        "    Y = np.asarray(y_true)\n",
        "    return X_scaled, Y, means, stds\n",
        "\n",
        "def get_test_features(test_words, ngram_counts, means, stds):\n",
        "\n",
        "    ## YOUR CODE HERE\n",
        "    # TODO: do the similar thing, except using means and stds as given (from training data)\n",
        "    features = []\n",
        "    for word in test_words:\n",
        "        length_feature = len(word) # word length feature\n",
        "        frequency_feature = ngram_counts.get(word, 0) # unigram frequency feature\n",
        "        syllable_feature = syllables.estimate(word)\n",
        "        features.append([length_feature, frequency_feature, syllable_feature])\n",
        "\n",
        "    X = np.asarray(features)\n",
        "    X_scaled = (X - means) / stds # 标准化/归一化\n",
        "\n",
        "    return X_scaled"
      ],
      "metadata": {
        "id": "YEkrjHTcEUiu",
        "ExecuteTime": {
          "end_time": "2024-09-14T22:20:44.503774Z",
          "start_time": "2024-09-14T22:20:44.492656Z"
        }
      },
      "execution_count": 102,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# PennGrader - DO NOT CHANGE\n",
        "X_train, Y_train, means, stds = get_training_features(train_data, ngram_counts)\n",
        "X_dev = get_test_features(dev_data[0], ngram_counts, means, stds)\n",
        "\n",
        "train_feats = (X_train, Y_train, means, stds)\n",
        "test_feats = (X_dev)\n",
        "\n",
        "grader.grade(test_case_id = 'test_q30_test_feature_shapes', answer = (train_feats, test_feats))"
      ],
      "metadata": {
        "id": "EX1yJMFvIqo6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "86ad9c58-a27c-487f-d01e-be797d348b37",
        "ExecuteTime": {
          "end_time": "2024-09-14T18:32:27.588207Z",
          "start_time": "2024-09-14T18:32:26.314309Z"
        }
      },
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Correct! You earned 3/3 points. You are a star!\n",
            "\n",
            "Your submission has been successfully recorded in the gradebook.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Once we have these feature arrays, we can fit a Naive Bayes classifier using the following commands:\n",
        "```\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "clf = GaussianNB()\n",
        "clf.fit(X_train, Y)\n",
        "```\n",
        "Finally, to use your model to predict the labels for a set of words, you only need one numpy array: `X_test`, an `m` by `n` array, where `m` is the number of words in the test set, and `n` is the number of features for each word. Note that the `n` used here is the same as the `n` in `X_train`. Then, we can use our classifier to predict labels using the following command:\n",
        "\n",
        "```\n",
        "Y_pred = clf.predict(X_test)\n",
        "```"
      ],
      "metadata": {
        "id": "dAd7V6R4GLP-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- **Problem 3.1**: Fill in the function `naive_bayes(train_data, dev_data, ngram_counts)`. This function will train a Naive Bayes classifier on the training data using **word length** and **word frequency** as features, and returns your model’s predictions on the training data and the development data individually.\n",
        "    - **NOTE**: Before training and testing a classifier, it is generally important to normalize your features. This means that you need to find the mean and standard deviation (sd) of a feature. Then, for each row, perform the following transformation: `X_scaled = (X_original - mean)/sd`. **Be sure to always use the means and standard deviations from the training data**.\n",
        "    - **Optional**: You can include more features if you want to, e.g. [the count of syllabus](https://github.com/prosegrinder/python-syllables)\n"
      ],
      "metadata": {
        "id": "vOFLzpw3ZApH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.naive_bayes import GaussianNB"
      ],
      "metadata": {
        "id": "mQcxSw3B4EWx",
        "ExecuteTime": {
          "end_time": "2024-09-14T18:32:33.086666Z",
          "start_time": "2024-09-14T18:32:33.076704Z"
        }
      },
      "execution_count": 104,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Trains a Naive Bayes classifier using length and frequency features\n",
        "def naive_bayes(train_data, dev_data, ngram_counts):\n",
        "    # TODO\n",
        "    # 1. Gets the features from the training data, and trains the model\n",
        "    # 2. Train model & inference on test_words\n",
        "    X_train, Y, means, stds = get_training_features(train_data, ngram_counts)\n",
        "    X_dev = get_test_features(dev_data, ngram_counts, means, stds) # X_dev <=> X_test\n",
        "\n",
        "    clf = GaussianNB() # model\n",
        "    clf.fit(X_train, Y) # train model\n",
        "    train_pred, dev_pred = clf.predict(X_train), clf.predict(X_dev)\n",
        "\n",
        "    return train_pred, dev_pred"
      ],
      "metadata": {
        "id": "HDy-VjftqUoC",
        "ExecuteTime": {
          "end_time": "2024-09-14T18:32:35.982596Z",
          "start_time": "2024-09-14T18:32:35.965824Z"
        }
      },
      "execution_count": 105,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- **Answer 3.1:** Please report the precision, recall, and f-score on both the training data and the development data.\n",
        "```\n",
        "Training Data:\n",
        "Precision: 0.5070296141190548\n",
        "Recall: 0.9792027729636048\n",
        "F1 Score: 0.6681119432400474\n",
        "```\n",
        "```\n",
        "Development Data:\n",
        "Precision: 0.4821852731591449\n",
        "Recall: 0.9712918660287081\n",
        "F1 Score: 0.6444444444444445\n",
        "```"
      ],
      "metadata": {
        "id": "Ss589ydpGSY1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# report train/development metrics!\n",
        "dev_text, dev_labels = dev_data\n",
        "train_text, train_labels = train_data\n",
        "\n",
        "train_pred, dev_pred = naive_bayes(train_data, dev_text, ngram_counts)\n",
        "train_precision = get_precision(train_labels, train_pred)\n",
        "train_recall = get_recall(train_labels, train_pred)\n",
        "train_f = get_fscore(train_labels, train_pred)\n",
        "print('Training Data')\n",
        "print(f\"Precision: {train_precision}\")\n",
        "print(f\"Recall: {train_recall}\")\n",
        "print(f\"F1 Score: {train_f}\")\n",
        "\n",
        "dev_precision = get_precision(dev_labels, dev_pred)\n",
        "dev_recall = get_recall(dev_labels, dev_pred)\n",
        "dev_f = get_fscore(dev_labels, dev_pred)\n",
        "# Report the precision, recall, and f-score on the development data\n",
        "print('\\nDevelopment Data')\n",
        "print(f\"Precision: {dev_precision}\")\n",
        "print(f\"Recall: {dev_recall}\")\n",
        "print(f\"F1 Score: {dev_f}\")"
      ],
      "metadata": {
        "id": "aC3BVu5o_X5H",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e85a7b5f-3972-4df7-8a12-40a46bfdd5fe",
        "ExecuteTime": {
          "end_time": "2024-09-14T18:32:39.396502Z",
          "start_time": "2024-09-14T18:32:39.150041Z"
        }
      },
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Data\n",
            "Precision: 0.5070296141190548\n",
            "Recall: 0.9792027729636048\n",
            "F1 Score: 0.6681119432400474\n",
            "\n",
            "Development Data\n",
            "Precision: 0.4821852731591449\n",
            "Recall: 0.9712918660287081\n",
            "F1 Score: 0.6444444444444445\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# PennGrader - DO NOT CHANGE\n",
        "train_pred, mini_test_pred = naive_bayes(train_data, mini_test_words, ngram_counts)\n",
        "grader.grade(test_case_id = 'test_naive_bayes', answer = mini_test_pred)"
      ],
      "metadata": {
        "id": "dqKUYfbtrVkx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9331807b-3899-4a08-de04-8bfd4d1e3beb",
        "ExecuteTime": {
          "end_time": "2024-09-14T18:33:01.716415Z",
          "start_time": "2024-09-14T18:33:01.059230Z"
        }
      },
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Correct! You earned 3/3 points. You are a star!\n",
            "\n",
            "Your submission has been successfully recorded in the gradebook.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.2 Logistic Regression\n",
        "Next, you will use sklearn’s built-in Logistic Regression classifier. Again, we will use word length and word frequency as your two features. You should refer to [the online sklearn documentation](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html) when you are building your classifier. To import and use this model, use the following command:\n",
        "\n",
        "```\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "clf = LogisticRegression()\n",
        "```\n",
        "\n",
        "- **Problem 3.2**: For this problem, you will be filling in the function `logistic_regression(train_data, dev_data, ngram_counts)`. This function will train a `Logistic Regression` classifier on the training data, and returns your model’s predictions on the training data and the development data individually.\n"
      ],
      "metadata": {
        "id": "uo8GAjvxrVzw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Trains a logistic regression classifier using length and frequency features\n",
        "def logistic_regression(train_data, dev_data, ngram_counts):\n",
        "    ## TODO\n",
        "    X_train, Y, means, stds = get_training_features(train_data, ngram_counts)\n",
        "    X_dev = get_test_features(dev_data, ngram_counts, means, stds) # X_dev <=> X_test\n",
        "\n",
        "    clf = LogisticRegression() # model\n",
        "    clf.fit(X_train, Y) # train model\n",
        "    train_pred, dev_pred = clf.predict(X_train), clf.predict(X_dev)\n",
        "\n",
        "    return train_pred, dev_pred"
      ],
      "metadata": {
        "id": "ggRdb6zYrVgN",
        "ExecuteTime": {
          "end_time": "2024-09-14T18:33:03.838186Z",
          "start_time": "2024-09-14T18:33:03.830735Z"
        }
      },
      "execution_count": 108,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- **Answer 3.2:** Please report the precision, recall, and f-score on both the training data and the development data.\n",
        "```\n",
        "Training Data:\n",
        "Precision: 0.7308435286542176\n",
        "Recall: 0.6556903523974581\n",
        "F1 Score: 0.6912302070645554\n",
        "```\n",
        "```\n",
        "Development Data:\n",
        "Precision: 0.7428571428571429\n",
        "Recall: 0.6842105263157895\n",
        "F1 Score: 0.7123287671232877\n",
        "```"
      ],
      "metadata": {
        "id": "PDH4MMIy_kke"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dev_text, dev_labels = dev_data\n",
        "train_text, train_labels = train_data\n",
        "\n",
        "train_pred, dev_pred = logistic_regression(train_data, dev_text, ngram_counts)\n",
        "train_precision = get_precision(train_labels, train_pred)\n",
        "train_recall = get_recall(train_labels, train_pred)\n",
        "train_f = get_fscore(train_labels, train_pred)\n",
        "print('Training Data')\n",
        "print(f\"Precision: {train_precision}\")\n",
        "print(f\"Recall: {train_recall}\")\n",
        "print(f\"F1 Score: {train_f}\")\n",
        "\n",
        "dev_precision = get_precision(dev_labels, dev_pred)\n",
        "dev_recall = get_recall(dev_labels, dev_pred)\n",
        "dev_f = get_fscore(dev_labels, dev_pred)\n",
        "# Report the precision, recall, and f-score on the development data\n",
        "print('\\nDevelopment Data')\n",
        "print(f\"Precision: {dev_precision}\")\n",
        "print(f\"Recall: {dev_recall}\")\n",
        "print(f\"F1 Score: {dev_f}\")"
      ],
      "metadata": {
        "id": "emRXThKD_noX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9aafb3f3-6e92-4e7d-b496-1164805869b8",
        "ExecuteTime": {
          "end_time": "2024-09-14T18:33:06.944925Z",
          "start_time": "2024-09-14T18:33:06.360407Z"
        }
      },
      "execution_count": 109,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Data\n",
            "Precision: 0.7308435286542176\n",
            "Recall: 0.6556903523974581\n",
            "F1 Score: 0.6912302070645554\n",
            "\n",
            "Development Data\n",
            "Precision: 0.7428571428571429\n",
            "Recall: 0.6842105263157895\n",
            "F1 Score: 0.7123287671232877\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# PennGrader - DO NOT CHANGE\n",
        "train_pred, mini_test_pred = logistic_regression(train_data, mini_test_words, ngram_counts)\n",
        "grader.grade(test_case_id = 'test_logistic', answer = mini_test_pred)"
      ],
      "metadata": {
        "id": "URxmIQiNTBMQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "370ca8ca-3272-4d34-a160-943eb0cf4bc3",
        "ExecuteTime": {
          "end_time": "2024-09-14T18:33:10.543915Z",
          "start_time": "2024-09-14T18:33:10.009214Z"
        }
      },
      "execution_count": 110,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Correct! You earned 3/3 points. You are a star!\n",
            "\n",
            "Your submission has been successfully recorded in the gradebook.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.3 Comparing Naive Bayes and Logistic Regression\n",
        "- **Answer 3.3**: After implementing Naive Bayes and Logistic Regression classifiers, you will notice that their performance is not identical, even though they are given the same data. **Write a paragraph below that discusses which model performed better on this task and what are the potential reasons.**\n",
        "    - [TODO: discussion of the differences]: **Logistic Regression** outperformed **Naive Bayes** on this task, achieving an F1 score of 0.71, with a precision of 0.74 and recall of 0.68 on the development set, compared to Naive Bayes' F1 score of 0.64, precision of 0.48, and recall of 0.97. The primary reason for Logistic Regression's superior performance lies in its ability to model feature interactions and capture the relationships between features, such as token lengths and word frequencies. Naive Bayes, with its assumption of feature independence, tends to oversimplify the data, leading to a higher recall but much lower precision, as it over-predicts the positive class. Consequently, Logistic Regression provides a more balanced performance, making it more effective for this task."
      ],
      "metadata": {
        "id": "qJoKAFpfrYQ7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Section 4. Build your own model\n",
        "Finally, the fun part! In this section, you will build your own classifier for the complex word identification task, and compare your results to that of your classmates. You will also perform an error analysis for your best performing model.\n",
        "\n",
        "You can choose any other types of classifier, and any additional features you can think of!\n",
        "- For classifiers, beyond `Naive Bayes` and `Logistic Regression`, you might consider trying `SVM`, `Decision Trees`, and `Random Forests`, among others.\n",
        "- Additional word features that you might consider include number of syllables, number of `WordNet` synonyms, and number of `WordNet` senses. To use WordNet in Python, refer to [this documentation](http://www.nltk.org/howto/wordnet.html).\n",
        "- You could also include sentence-based complexity features, such as length of the sentence, average word length, and average word frequency.\n",
        "\n",
        "When trying different classifiers, we recommend that you train on training data, and test on the development data, like the previous sections.\n",
        "\n",
        "In the following cell, please include a description of **all of the models** and **features** that you tried. To receive full credit, you MUST try **at least 1 type of classifier** (not including `Naive Bayes` and `Logistic Regression`), and **at least two features** (not including length and frequency).\n",
        "\n",
        "**Note**: You can also tune the parameters of your model, e.g. what type of kernel to use. This is NOT required, as some of you may not be that familiar with this."
      ],
      "metadata": {
        "id": "BFBpm0kdqU2V"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4.1 Your Own Model\n",
        "\n",
        "An important part of text classification tasks is to determine what your model is getting correct, and what your model is getting wrong. For this problem, you must train your best model on the training data, and report the precision, recall, and f-score on the development data. In order to receive full credit, your model must be able to outperform all of the baselines."
      ],
      "metadata": {
        "id": "O1jCYFXIra-O"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- **Answer 4.1**: Train your best model on the training data, and report the precision, recall, and f-score on the development data\n",
        "\n",
        "```\n",
        "Development Data:\n",
        "Precision: 0.7226720647773279\n",
        "Recall: 0.854066985645933\n",
        "F1 Score: 0.7828947368421051\n",
        "```"
      ],
      "metadata": {
        "id": "mGQck2ObXjqi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Feature one:** get the length of word tokenizer"
      ],
      "metadata": {
        "id": "hdoVZ_p1lAri"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# feature 1: get the length of word tokenizer\n",
        "from transformers import AutoTokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained('google-bert/bert-base-uncased')\n",
        "\n",
        "def get_token_feature(tokenizer, word):\n",
        "    token_ids = tokenizer.encode(word, add_special_tokens=False)\n",
        "    return len(token_ids)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 304,
          "referenced_widgets": [
            "40c4ff0240da4c819297cd36f3fbbe82",
            "c4da8d68af2c472ea3783a1329da8271",
            "5a4f2457b5c6488faad8edb17076a720",
            "0b4fec16ee514996aeeb8ece1f40a940",
            "c8817827b02e415d8426320bf6c9d810",
            "65d9ba835b9942d49750c1377c0fec38",
            "38bb6d41e22a442ab1aca7606a7d7ac5",
            "8ff8dcd68684435cbac70b86e4cf8425",
            "1c75cb159bfa485ebe07a7e849d508f1",
            "289b1c789b9143a7b0d0cb1503f2fca8",
            "11437899c59e4c7784e5d0597daaa389",
            "de97ce72544542e292a4679717d891ea",
            "cefc1d4e60134315a511b58a5dca9311",
            "ba2b844283c44e51979a95b53d7c9bc6",
            "a19eff763fc14fc890d90da582ad47b7",
            "ee97b28bf4a64cc790ec13e4b6afef4e",
            "5ba15e7c9f4c4326a6d0d74422a8da3b",
            "d5d0a3aa686c4616a18f659339a50acf",
            "24b913a23878433ca51c527974b30352",
            "29b986af199e4eccaf4727d80678adda",
            "bd2e23feeff74ec5be8c2412f95ee5f5",
            "4449b6faefef4980a464d2af94f8c677",
            "2b056e39cb284308af5db3d03b175cab",
            "247fdc3d8daf44a38f622cee33baf3d4",
            "a654f6beb9d4407a8e6ad5a04a4a9f97",
            "0221f4a1c91b4637a8e7383fb0d60251",
            "93fd40309d6d483ca5b9c70619494fa9",
            "04781aa753af49bab21769037682e052",
            "e7a23fd2ef934f98b6794432203e47cd",
            "077c74fb2d19408686a70bbd5482d6b1",
            "54249bc9ae9247ca81579261c6a8d255",
            "bac9f49fbc6947b389ba4b54ec934a85",
            "c431dbafcd5141cfad7120c5dc788502",
            "1c0132d0960146d3a3916d049372da79",
            "67da75eaf69a4379a296c72fd44aafc2",
            "3cfd64a7b0754bff841ced26acc0035e",
            "f2d943e48dd04d4391a9c39bef64d479",
            "c0ba67cac8c94e94822569ed650c0476",
            "c258dcd55d5b40fa8d208236a42e3688",
            "879f34fa64c0434b94fdd64714277506",
            "08783f3908714f059c610b0a7f636cbd",
            "58e387ac534f489dbe083a2655ef408e",
            "15feaaa472b74c3b919ae599093381ab",
            "3d1d17ed38c24aaf9095855f7df1573f"
          ]
        },
        "id": "VF2_wcFBNjYn",
        "outputId": "cfdcea9e-d0d7-4526-a7a2-b6c69b6324fd"
      },
      "execution_count": 111,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "40c4ff0240da4c819297cd36f3fbbe82"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "de97ce72544542e292a4679717d891ea"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2b056e39cb284308af5db3d03b175cab"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1c0132d0960146d3a3916d049372da79"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Feature two:** get the mean of the Word2Vec vector"
      ],
      "metadata": {
        "id": "kaif2ci3okYW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from gensim.models import Word2Vec\n",
        "import numpy as np\n",
        "\n",
        "def train_word2vec(twords, vector_size=100, window=5, min_count=1):\n",
        "    model = Word2Vec(sentences=[twords], vector_size=vector_size, window=window, min_count=min_count, workers=4)\n",
        "    return model\n",
        "\n",
        "def word2vector(model, word, feature_type=\"mean\"):\n",
        "    if word in model.wv:\n",
        "        vector = model.wv[word]\n",
        "    return np.mean(vector)"
      ],
      "metadata": {
        "id": "IPCgy_lf6yU0"
      },
      "execution_count": 112,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Feature three:** NLTK"
      ],
      "metadata": {
        "id": "_B6uFKsgoOKI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.corpus import wordnet as wn\n",
        "\n",
        "nltk.download('wordnet')\n",
        "nltk.download('cmudict')\n",
        "\n",
        "def get_wordnet_info(word):\n",
        "    synsets = wn.synsets(word)\n",
        "\n",
        "    synonyms = set()\n",
        "    for synset in synsets:\n",
        "        for lemma in synset.lemmas():\n",
        "            synonyms.add(lemma.name())\n",
        "\n",
        "    num_senses = len(synsets)\n",
        "    num_synonyms = len(synonyms)\n",
        "\n",
        "    return num_senses, num_synonyms"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JS7tr_u2Njnv",
        "outputId": "a3d611ca-34f0-4185-b661-e96065f811bc"
      },
      "execution_count": 113,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data] Downloading package cmudict to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/cmudict.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_training_features_mymodel(train_data, ngram_counts):\n",
        "    words, y_true = train_data\n",
        "    features = []\n",
        "    tokenizer = AutoTokenizer.from_pretrained('google-bert/bert-base-uncased')\n",
        "    word2vec_model = train_word2vec(words, vector_size=100, window=5, min_count=1)\n",
        "\n",
        "    for word in words:\n",
        "        length_feature = len(word) # word length feature\n",
        "        frequency_feature = ngram_counts.get(word, 0) # unigram frequency feature\n",
        "        syllable_feature = syllables.estimate(word)\n",
        "        token_feature = get_token_feature(tokenizer, word)\n",
        "        word2vec_feature = word2vector(word2vec_model, word, feature_type=\"mean\")\n",
        "        num_senses, num_synonyms = get_wordnet_info(word)\n",
        "        features.append([length_feature, frequency_feature, syllable_feature, token_feature, word2vec_feature, num_senses, num_synonyms])\n",
        "\n",
        "    X = np.asarray(features)\n",
        "    ## YOUR CODE HERE\n",
        "    # TODO: calculate the mean and std of the vectorized data (X)\n",
        "    means = np.mean(X, axis=0)\n",
        "    stds = np.std(X, axis=0)\n",
        "\n",
        "    stds[stds == 0] = 1\n",
        "\n",
        "    # TODO: calculate the scaled data, with the mean and std you just calculated\n",
        "    X_scaled = (X - means) / stds # 标准化/归一化\n",
        "\n",
        "    Y = np.asarray(y_true)\n",
        "    return X_scaled, Y, means, stds\n",
        "\n",
        "def get_test_features_mymodel(test_words, ngram_counts, means, stds):\n",
        "\n",
        "    ## YOUR CODE HERE\n",
        "    # TODO: do the similar thing, except using means and stds as given (from training data)\n",
        "    features = []\n",
        "    tokenizer = AutoTokenizer.from_pretrained('google-bert/bert-base-uncased')\n",
        "    word2vec_model = train_word2vec(test_words, vector_size=100, window=5, min_count=1)\n",
        "\n",
        "    for word in test_words:\n",
        "        length_feature = len(word) # word length feature\n",
        "        frequency_feature = ngram_counts.get(word, 0) # unigram frequency feature\n",
        "        syllable_feature = syllables.estimate(word)\n",
        "        token_feature = get_token_feature(tokenizer, word)\n",
        "        word2vec_feature = word2vector(word2vec_model, word, feature_type=\"mean\")\n",
        "        num_senses, num_synonyms = get_wordnet_info(word)\n",
        "        features.append([length_feature, frequency_feature, syllable_feature, token_feature, word2vec_feature, num_senses, num_synonyms])\n",
        "\n",
        "    X = np.asarray(features)\n",
        "    X_scaled = (X - means) / stds # 标准化/归一化\n",
        "\n",
        "    return X_scaled"
      ],
      "metadata": {
        "id": "ACQlpYirNjqB"
      },
      "execution_count": 114,
      "outputs": []
    },
    {
      "cell_type": "code",
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "class LSTMModel(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, num_layers, output_size, bidirectional=False):\n",
        "        super(LSTMModel, self).__init__()\n",
        "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True, bidirectional=bidirectional, dropout=0.5)\n",
        "        self.fc = nn.Sequential(\n",
        "            nn.Dropout(0.4),\n",
        "            nn.Linear(hidden_size * (2 if bidirectional else 1), hidden_size),\n",
        "            nn.LeakyReLU(negative_slope=0.01),\n",
        "            nn.Linear(hidden_size, output_size)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        batch_size = x.size(0)\n",
        "        h_0 = torch.zeros(self.lstm.num_layers * (2 if self.lstm.bidirectional else 1), batch_size, self.lstm.hidden_size).to(x.device)\n",
        "        c_0 = torch.zeros(self.lstm.num_layers * (2 if self.lstm.bidirectional else 1), batch_size, self.lstm.hidden_size).to(x.device)\n",
        "\n",
        "        out, _ = self.lstm(x, (h_0, c_0))\n",
        "        out = out[:, -1, :]\n",
        "        out = self.fc(out)\n",
        "        return torch.sigmoid(out)\n",
        "\n",
        "def train_lstm_model(train_data, dev_data, ngram_counts, input_size=100, hidden_size=128, num_layers=3, output_size=1, epochs=2000, learning_rate=0.001, patience=5):\n",
        "    X_train, Y_train, means, stds = get_training_features_mymodel(train_data, ngram_counts)\n",
        "    X_dev = get_test_features_mymodel(dev_data, ngram_counts, means, stds)\n",
        "\n",
        "    X_train = torch.tensor(X_train, dtype=torch.float32).unsqueeze(1)\n",
        "    Y_train = torch.tensor(Y_train, dtype=torch.float32).unsqueeze(1)\n",
        "    X_dev = torch.tensor(X_dev, dtype=torch.float32).unsqueeze(1)\n",
        "\n",
        "    model = LSTMModel(input_size=X_train.shape[2], hidden_size=hidden_size, num_layers=num_layers, output_size=output_size)\n",
        "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "    model = model.to(device)\n",
        "\n",
        "    criterion = nn.BCELoss()\n",
        "    optimizer = optim.Adam(model.parameters(), lr=learning_rate, weight_decay=1e-5)\n",
        "\n",
        "    best_loss = float('inf')\n",
        "    trigger_times = 0\n",
        "    model.train()\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        model.zero_grad()\n",
        "        output = model(X_train.to(device))\n",
        "        loss = criterion(output, Y_train.to(device))\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        if (epoch + 1) % 2 == 0:\n",
        "            print(f'Epoch [{epoch+1}/{epochs}], Loss: {loss.item():.4f}')\n",
        "\n",
        "        model.eval()\n",
        "        with torch.no_grad():\n",
        "            val_output = model(X_dev.to(device))\n",
        "            val_loss = criterion(val_output, torch.zeros_like(val_output))\n",
        "            if val_loss < best_loss:\n",
        "                best_loss = val_loss\n",
        "                trigger_times = 0\n",
        "            else:\n",
        "                trigger_times += 1\n",
        "        model.train()\n",
        "\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        train_pred = (model(X_train.to(device)) > 0.5).cpu().numpy().astype(int)\n",
        "        dev_pred = (model(X_dev.to(device)) > 0.5).cpu().numpy().astype(int)\n",
        "\n",
        "    return train_pred, dev_pred\n"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-09-14T22:27:46.730532Z",
          "start_time": "2024-09-14T22:27:46.688805Z"
        },
        "id": "mjEzrugoJome"
      },
      "execution_count": 115
    },
    {
      "cell_type": "code",
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [2/1000], Loss: 0.6916\n",
            "Epoch [4/1000], Loss: 0.6899\n",
            "Epoch [6/1000], Loss: 0.6883\n",
            "Epoch [8/1000], Loss: 0.6868\n",
            "Epoch [10/1000], Loss: 0.6850\n",
            "Epoch [12/1000], Loss: 0.6831\n",
            "Epoch [14/1000], Loss: 0.6808\n",
            "Epoch [16/1000], Loss: 0.6774\n",
            "Epoch [18/1000], Loss: 0.6734\n",
            "Epoch [20/1000], Loss: 0.6679\n",
            "Epoch [22/1000], Loss: 0.6603\n",
            "Epoch [24/1000], Loss: 0.6491\n",
            "Epoch [26/1000], Loss: 0.6345\n",
            "Epoch [28/1000], Loss: 0.6161\n",
            "Epoch [30/1000], Loss: 0.5982\n",
            "Epoch [32/1000], Loss: 0.5776\n",
            "Epoch [34/1000], Loss: 0.5614\n",
            "Epoch [36/1000], Loss: 0.5482\n",
            "Epoch [38/1000], Loss: 0.5392\n",
            "Epoch [40/1000], Loss: 0.5335\n",
            "Epoch [42/1000], Loss: 0.5284\n",
            "Epoch [44/1000], Loss: 0.5298\n",
            "Epoch [46/1000], Loss: 0.5313\n",
            "Epoch [48/1000], Loss: 0.5276\n",
            "Epoch [50/1000], Loss: 0.5224\n",
            "Epoch [52/1000], Loss: 0.5201\n",
            "Epoch [54/1000], Loss: 0.5195\n",
            "Epoch [56/1000], Loss: 0.5187\n",
            "Epoch [58/1000], Loss: 0.5169\n",
            "Epoch [60/1000], Loss: 0.5143\n",
            "Epoch [62/1000], Loss: 0.5142\n",
            "Epoch [64/1000], Loss: 0.5139\n",
            "Epoch [66/1000], Loss: 0.5160\n",
            "Epoch [68/1000], Loss: 0.5130\n",
            "Epoch [70/1000], Loss: 0.5118\n",
            "Epoch [72/1000], Loss: 0.5107\n",
            "Epoch [74/1000], Loss: 0.5105\n",
            "Epoch [76/1000], Loss: 0.5120\n",
            "Epoch [78/1000], Loss: 0.5093\n",
            "Epoch [80/1000], Loss: 0.5085\n",
            "Epoch [82/1000], Loss: 0.5099\n",
            "Epoch [84/1000], Loss: 0.5102\n",
            "Epoch [86/1000], Loss: 0.5096\n",
            "Epoch [88/1000], Loss: 0.5099\n",
            "Epoch [90/1000], Loss: 0.5079\n",
            "Epoch [92/1000], Loss: 0.5085\n",
            "Epoch [94/1000], Loss: 0.5046\n",
            "Epoch [96/1000], Loss: 0.5054\n",
            "Epoch [98/1000], Loss: 0.5053\n",
            "Epoch [100/1000], Loss: 0.5073\n",
            "Epoch [102/1000], Loss: 0.5066\n",
            "Epoch [104/1000], Loss: 0.5053\n",
            "Epoch [106/1000], Loss: 0.5047\n",
            "Epoch [108/1000], Loss: 0.5048\n",
            "Epoch [110/1000], Loss: 0.5037\n",
            "Epoch [112/1000], Loss: 0.5047\n",
            "Epoch [114/1000], Loss: 0.5040\n",
            "Epoch [116/1000], Loss: 0.5055\n",
            "Epoch [118/1000], Loss: 0.5029\n",
            "Epoch [120/1000], Loss: 0.5004\n",
            "Epoch [122/1000], Loss: 0.5034\n",
            "Epoch [124/1000], Loss: 0.5041\n",
            "Epoch [126/1000], Loss: 0.5019\n",
            "Epoch [128/1000], Loss: 0.5055\n",
            "Epoch [130/1000], Loss: 0.5029\n",
            "Epoch [132/1000], Loss: 0.5013\n",
            "Epoch [134/1000], Loss: 0.5030\n",
            "Epoch [136/1000], Loss: 0.5039\n",
            "Epoch [138/1000], Loss: 0.5028\n",
            "Epoch [140/1000], Loss: 0.5017\n",
            "Epoch [142/1000], Loss: 0.5004\n",
            "Epoch [144/1000], Loss: 0.4994\n",
            "Epoch [146/1000], Loss: 0.5013\n",
            "Epoch [148/1000], Loss: 0.5000\n",
            "Epoch [150/1000], Loss: 0.5000\n",
            "Epoch [152/1000], Loss: 0.4988\n",
            "Epoch [154/1000], Loss: 0.5017\n",
            "Epoch [156/1000], Loss: 0.5005\n",
            "Epoch [158/1000], Loss: 0.5004\n",
            "Epoch [160/1000], Loss: 0.4993\n",
            "Epoch [162/1000], Loss: 0.4982\n",
            "Epoch [164/1000], Loss: 0.4971\n",
            "Epoch [166/1000], Loss: 0.4988\n",
            "Epoch [168/1000], Loss: 0.4982\n",
            "Epoch [170/1000], Loss: 0.4989\n",
            "Epoch [172/1000], Loss: 0.4989\n",
            "Epoch [174/1000], Loss: 0.4977\n",
            "Epoch [176/1000], Loss: 0.4986\n",
            "Epoch [178/1000], Loss: 0.4968\n",
            "Epoch [180/1000], Loss: 0.4983\n",
            "Epoch [182/1000], Loss: 0.4979\n",
            "Epoch [184/1000], Loss: 0.4961\n",
            "Epoch [186/1000], Loss: 0.4967\n",
            "Epoch [188/1000], Loss: 0.4976\n",
            "Epoch [190/1000], Loss: 0.4958\n",
            "Epoch [192/1000], Loss: 0.4929\n",
            "Epoch [194/1000], Loss: 0.4974\n",
            "Epoch [196/1000], Loss: 0.4975\n",
            "Epoch [198/1000], Loss: 0.4948\n",
            "Epoch [200/1000], Loss: 0.4964\n",
            "Epoch [202/1000], Loss: 0.4937\n",
            "Epoch [204/1000], Loss: 0.4922\n",
            "Epoch [206/1000], Loss: 0.4936\n",
            "Epoch [208/1000], Loss: 0.4952\n",
            "Epoch [210/1000], Loss: 0.4942\n",
            "Epoch [212/1000], Loss: 0.4908\n",
            "Epoch [214/1000], Loss: 0.4907\n",
            "Epoch [216/1000], Loss: 0.4921\n",
            "Epoch [218/1000], Loss: 0.4899\n",
            "Epoch [220/1000], Loss: 0.4906\n",
            "Epoch [222/1000], Loss: 0.4920\n",
            "Epoch [224/1000], Loss: 0.4918\n",
            "Epoch [226/1000], Loss: 0.4889\n",
            "Epoch [228/1000], Loss: 0.4895\n",
            "Epoch [230/1000], Loss: 0.4908\n",
            "Epoch [232/1000], Loss: 0.4897\n",
            "Epoch [234/1000], Loss: 0.4885\n",
            "Epoch [236/1000], Loss: 0.4876\n",
            "Epoch [238/1000], Loss: 0.4910\n",
            "Epoch [240/1000], Loss: 0.4917\n",
            "Epoch [242/1000], Loss: 0.4888\n",
            "Epoch [244/1000], Loss: 0.4863\n",
            "Epoch [246/1000], Loss: 0.4863\n",
            "Epoch [248/1000], Loss: 0.4901\n",
            "Epoch [250/1000], Loss: 0.4889\n",
            "Epoch [252/1000], Loss: 0.4866\n",
            "Epoch [254/1000], Loss: 0.4907\n",
            "Epoch [256/1000], Loss: 0.4881\n",
            "Epoch [258/1000], Loss: 0.4870\n",
            "Epoch [260/1000], Loss: 0.4883\n",
            "Epoch [262/1000], Loss: 0.4895\n",
            "Epoch [264/1000], Loss: 0.4862\n",
            "Epoch [266/1000], Loss: 0.4849\n",
            "Epoch [268/1000], Loss: 0.4866\n",
            "Epoch [270/1000], Loss: 0.4848\n",
            "Epoch [272/1000], Loss: 0.4855\n",
            "Epoch [274/1000], Loss: 0.4881\n",
            "Epoch [276/1000], Loss: 0.4849\n",
            "Epoch [278/1000], Loss: 0.4862\n",
            "Epoch [280/1000], Loss: 0.4831\n",
            "Epoch [282/1000], Loss: 0.4873\n",
            "Epoch [284/1000], Loss: 0.4842\n",
            "Epoch [286/1000], Loss: 0.4833\n",
            "Epoch [288/1000], Loss: 0.4841\n",
            "Epoch [290/1000], Loss: 0.4846\n",
            "Epoch [292/1000], Loss: 0.4870\n",
            "Epoch [294/1000], Loss: 0.4827\n",
            "Epoch [296/1000], Loss: 0.4835\n",
            "Epoch [298/1000], Loss: 0.4843\n",
            "Epoch [300/1000], Loss: 0.4822\n",
            "Epoch [302/1000], Loss: 0.4852\n",
            "Epoch [304/1000], Loss: 0.4838\n",
            "Epoch [306/1000], Loss: 0.4874\n",
            "Epoch [308/1000], Loss: 0.4819\n",
            "Epoch [310/1000], Loss: 0.4835\n",
            "Epoch [312/1000], Loss: 0.4833\n",
            "Epoch [314/1000], Loss: 0.4846\n",
            "Epoch [316/1000], Loss: 0.4820\n",
            "Epoch [318/1000], Loss: 0.4819\n",
            "Epoch [320/1000], Loss: 0.4826\n",
            "Epoch [322/1000], Loss: 0.4816\n",
            "Epoch [324/1000], Loss: 0.4829\n",
            "Epoch [326/1000], Loss: 0.4815\n",
            "Epoch [328/1000], Loss: 0.4810\n",
            "Epoch [330/1000], Loss: 0.4820\n",
            "Epoch [332/1000], Loss: 0.4796\n",
            "Epoch [334/1000], Loss: 0.4816\n",
            "Epoch [336/1000], Loss: 0.4844\n",
            "Epoch [338/1000], Loss: 0.4787\n",
            "Epoch [340/1000], Loss: 0.4820\n",
            "Epoch [342/1000], Loss: 0.4788\n",
            "Epoch [344/1000], Loss: 0.4802\n",
            "Epoch [346/1000], Loss: 0.4808\n",
            "Epoch [348/1000], Loss: 0.4811\n",
            "Epoch [350/1000], Loss: 0.4784\n",
            "Epoch [352/1000], Loss: 0.4767\n",
            "Epoch [354/1000], Loss: 0.4790\n",
            "Epoch [356/1000], Loss: 0.4782\n",
            "Epoch [358/1000], Loss: 0.4769\n",
            "Epoch [360/1000], Loss: 0.4787\n",
            "Epoch [362/1000], Loss: 0.4782\n",
            "Epoch [364/1000], Loss: 0.4788\n",
            "Epoch [366/1000], Loss: 0.4773\n",
            "Epoch [368/1000], Loss: 0.4765\n",
            "Epoch [370/1000], Loss: 0.4783\n",
            "Epoch [372/1000], Loss: 0.4799\n",
            "Epoch [374/1000], Loss: 0.4767\n",
            "Epoch [376/1000], Loss: 0.4735\n",
            "Epoch [378/1000], Loss: 0.4768\n",
            "Epoch [380/1000], Loss: 0.4776\n",
            "Epoch [382/1000], Loss: 0.4762\n",
            "Epoch [384/1000], Loss: 0.4819\n",
            "Epoch [386/1000], Loss: 0.4777\n",
            "Epoch [388/1000], Loss: 0.4764\n",
            "Epoch [390/1000], Loss: 0.4789\n",
            "Epoch [392/1000], Loss: 0.4779\n",
            "Epoch [394/1000], Loss: 0.4789\n",
            "Epoch [396/1000], Loss: 0.4785\n",
            "Epoch [398/1000], Loss: 0.4757\n",
            "Epoch [400/1000], Loss: 0.4767\n",
            "Epoch [402/1000], Loss: 0.4759\n",
            "Epoch [404/1000], Loss: 0.4769\n",
            "Epoch [406/1000], Loss: 0.4769\n",
            "Epoch [408/1000], Loss: 0.4762\n",
            "Epoch [410/1000], Loss: 0.4756\n",
            "Epoch [412/1000], Loss: 0.4734\n",
            "Epoch [414/1000], Loss: 0.4805\n",
            "Epoch [416/1000], Loss: 0.4755\n",
            "Epoch [418/1000], Loss: 0.4744\n",
            "Epoch [420/1000], Loss: 0.4715\n",
            "Epoch [422/1000], Loss: 0.4780\n",
            "Epoch [424/1000], Loss: 0.4743\n",
            "Epoch [426/1000], Loss: 0.4691\n",
            "Epoch [428/1000], Loss: 0.4771\n",
            "Epoch [430/1000], Loss: 0.4772\n",
            "Epoch [432/1000], Loss: 0.4751\n",
            "Epoch [434/1000], Loss: 0.4737\n",
            "Epoch [436/1000], Loss: 0.4732\n",
            "Epoch [438/1000], Loss: 0.4753\n",
            "Epoch [440/1000], Loss: 0.4739\n",
            "Epoch [442/1000], Loss: 0.4744\n",
            "Epoch [444/1000], Loss: 0.4740\n",
            "Epoch [446/1000], Loss: 0.4707\n",
            "Epoch [448/1000], Loss: 0.4742\n",
            "Epoch [450/1000], Loss: 0.4749\n",
            "Epoch [452/1000], Loss: 0.4755\n",
            "Epoch [454/1000], Loss: 0.4740\n",
            "Epoch [456/1000], Loss: 0.4719\n",
            "Epoch [458/1000], Loss: 0.4731\n",
            "Epoch [460/1000], Loss: 0.4727\n",
            "Epoch [462/1000], Loss: 0.4730\n",
            "Epoch [464/1000], Loss: 0.4729\n",
            "Epoch [466/1000], Loss: 0.4716\n",
            "Epoch [468/1000], Loss: 0.4738\n",
            "Epoch [470/1000], Loss: 0.4730\n",
            "Epoch [472/1000], Loss: 0.4719\n",
            "Epoch [474/1000], Loss: 0.4731\n",
            "Epoch [476/1000], Loss: 0.4763\n",
            "Epoch [478/1000], Loss: 0.4738\n",
            "Epoch [480/1000], Loss: 0.4725\n",
            "Epoch [482/1000], Loss: 0.4734\n",
            "Epoch [484/1000], Loss: 0.4738\n",
            "Epoch [486/1000], Loss: 0.4747\n",
            "Epoch [488/1000], Loss: 0.4745\n",
            "Epoch [490/1000], Loss: 0.4724\n",
            "Epoch [492/1000], Loss: 0.4737\n",
            "Epoch [494/1000], Loss: 0.4717\n",
            "Epoch [496/1000], Loss: 0.4709\n",
            "Epoch [498/1000], Loss: 0.4754\n",
            "Epoch [500/1000], Loss: 0.4727\n",
            "Epoch [502/1000], Loss: 0.4760\n",
            "Epoch [504/1000], Loss: 0.4736\n",
            "Epoch [506/1000], Loss: 0.4730\n",
            "Epoch [508/1000], Loss: 0.4758\n",
            "Epoch [510/1000], Loss: 0.4692\n",
            "Epoch [512/1000], Loss: 0.4740\n",
            "Epoch [514/1000], Loss: 0.4736\n",
            "Epoch [516/1000], Loss: 0.4731\n",
            "Epoch [518/1000], Loss: 0.4694\n",
            "Epoch [520/1000], Loss: 0.4769\n",
            "Epoch [522/1000], Loss: 0.4703\n",
            "Epoch [524/1000], Loss: 0.4741\n",
            "Epoch [526/1000], Loss: 0.4776\n",
            "Epoch [528/1000], Loss: 0.4737\n",
            "Epoch [530/1000], Loss: 0.4705\n",
            "Epoch [532/1000], Loss: 0.4696\n",
            "Epoch [534/1000], Loss: 0.4720\n",
            "Epoch [536/1000], Loss: 0.4720\n",
            "Epoch [538/1000], Loss: 0.4711\n",
            "Epoch [540/1000], Loss: 0.4728\n",
            "Epoch [542/1000], Loss: 0.4753\n",
            "Epoch [544/1000], Loss: 0.4729\n",
            "Epoch [546/1000], Loss: 0.4728\n",
            "Epoch [548/1000], Loss: 0.4715\n",
            "Epoch [550/1000], Loss: 0.4720\n",
            "Epoch [552/1000], Loss: 0.4733\n",
            "Epoch [554/1000], Loss: 0.4727\n",
            "Epoch [556/1000], Loss: 0.4749\n",
            "Epoch [558/1000], Loss: 0.4749\n",
            "Epoch [560/1000], Loss: 0.4726\n",
            "Epoch [562/1000], Loss: 0.4706\n",
            "Epoch [564/1000], Loss: 0.4729\n",
            "Epoch [566/1000], Loss: 0.4731\n",
            "Epoch [568/1000], Loss: 0.4706\n",
            "Epoch [570/1000], Loss: 0.4723\n",
            "Epoch [572/1000], Loss: 0.4746\n",
            "Epoch [574/1000], Loss: 0.4714\n",
            "Epoch [576/1000], Loss: 0.4726\n",
            "Epoch [578/1000], Loss: 0.4691\n",
            "Epoch [580/1000], Loss: 0.4716\n",
            "Epoch [582/1000], Loss: 0.4721\n",
            "Epoch [584/1000], Loss: 0.4713\n",
            "Epoch [586/1000], Loss: 0.4726\n",
            "Epoch [588/1000], Loss: 0.4720\n",
            "Epoch [590/1000], Loss: 0.4717\n",
            "Epoch [592/1000], Loss: 0.4709\n",
            "Epoch [594/1000], Loss: 0.4730\n",
            "Epoch [596/1000], Loss: 0.4716\n",
            "Epoch [598/1000], Loss: 0.4703\n",
            "Epoch [600/1000], Loss: 0.4733\n",
            "Epoch [602/1000], Loss: 0.4699\n",
            "Epoch [604/1000], Loss: 0.4724\n",
            "Epoch [606/1000], Loss: 0.4720\n",
            "Epoch [608/1000], Loss: 0.4695\n",
            "Epoch [610/1000], Loss: 0.4701\n",
            "Epoch [612/1000], Loss: 0.4739\n",
            "Epoch [614/1000], Loss: 0.4724\n",
            "Epoch [616/1000], Loss: 0.4737\n",
            "Epoch [618/1000], Loss: 0.4743\n",
            "Epoch [620/1000], Loss: 0.4728\n",
            "Epoch [622/1000], Loss: 0.4701\n",
            "Epoch [624/1000], Loss: 0.4695\n",
            "Epoch [626/1000], Loss: 0.4707\n",
            "Epoch [628/1000], Loss: 0.4725\n",
            "Epoch [630/1000], Loss: 0.4745\n",
            "Epoch [632/1000], Loss: 0.4691\n",
            "Epoch [634/1000], Loss: 0.4721\n",
            "Epoch [636/1000], Loss: 0.4699\n",
            "Epoch [638/1000], Loss: 0.4710\n",
            "Epoch [640/1000], Loss: 0.4715\n",
            "Epoch [642/1000], Loss: 0.4726\n",
            "Epoch [644/1000], Loss: 0.4707\n",
            "Epoch [646/1000], Loss: 0.4682\n",
            "Epoch [648/1000], Loss: 0.4701\n",
            "Epoch [650/1000], Loss: 0.4683\n",
            "Epoch [652/1000], Loss: 0.4705\n",
            "Epoch [654/1000], Loss: 0.4692\n",
            "Epoch [656/1000], Loss: 0.4700\n",
            "Epoch [658/1000], Loss: 0.4699\n",
            "Epoch [660/1000], Loss: 0.4697\n",
            "Epoch [662/1000], Loss: 0.4727\n",
            "Epoch [664/1000], Loss: 0.4704\n",
            "Epoch [666/1000], Loss: 0.4700\n",
            "Epoch [668/1000], Loss: 0.4685\n",
            "Epoch [670/1000], Loss: 0.4697\n",
            "Epoch [672/1000], Loss: 0.4693\n",
            "Epoch [674/1000], Loss: 0.4724\n",
            "Epoch [676/1000], Loss: 0.4704\n",
            "Epoch [678/1000], Loss: 0.4719\n",
            "Epoch [680/1000], Loss: 0.4685\n",
            "Epoch [682/1000], Loss: 0.4705\n",
            "Epoch [684/1000], Loss: 0.4703\n",
            "Epoch [686/1000], Loss: 0.4678\n",
            "Epoch [688/1000], Loss: 0.4683\n",
            "Epoch [690/1000], Loss: 0.4705\n",
            "Epoch [692/1000], Loss: 0.4711\n",
            "Epoch [694/1000], Loss: 0.4675\n",
            "Epoch [696/1000], Loss: 0.4682\n",
            "Epoch [698/1000], Loss: 0.4682\n",
            "Epoch [700/1000], Loss: 0.4696\n",
            "Epoch [702/1000], Loss: 0.4715\n",
            "Epoch [704/1000], Loss: 0.4690\n",
            "Epoch [706/1000], Loss: 0.4713\n",
            "Epoch [708/1000], Loss: 0.4719\n",
            "Epoch [710/1000], Loss: 0.4678\n",
            "Epoch [712/1000], Loss: 0.4729\n",
            "Epoch [714/1000], Loss: 0.4708\n",
            "Epoch [716/1000], Loss: 0.4698\n",
            "Epoch [718/1000], Loss: 0.4706\n",
            "Epoch [720/1000], Loss: 0.4703\n",
            "Epoch [722/1000], Loss: 0.4724\n",
            "Epoch [724/1000], Loss: 0.4713\n",
            "Epoch [726/1000], Loss: 0.4691\n",
            "Epoch [728/1000], Loss: 0.4719\n",
            "Epoch [730/1000], Loss: 0.4692\n",
            "Epoch [732/1000], Loss: 0.4676\n",
            "Epoch [734/1000], Loss: 0.4678\n",
            "Epoch [736/1000], Loss: 0.4715\n",
            "Epoch [738/1000], Loss: 0.4673\n",
            "Epoch [740/1000], Loss: 0.4690\n",
            "Epoch [742/1000], Loss: 0.4687\n",
            "Epoch [744/1000], Loss: 0.4691\n",
            "Epoch [746/1000], Loss: 0.4700\n",
            "Epoch [748/1000], Loss: 0.4741\n",
            "Epoch [750/1000], Loss: 0.4683\n",
            "Epoch [752/1000], Loss: 0.4683\n",
            "Epoch [754/1000], Loss: 0.4707\n",
            "Epoch [756/1000], Loss: 0.4694\n",
            "Epoch [758/1000], Loss: 0.4707\n",
            "Epoch [760/1000], Loss: 0.4671\n",
            "Epoch [762/1000], Loss: 0.4681\n",
            "Epoch [764/1000], Loss: 0.4684\n",
            "Epoch [766/1000], Loss: 0.4677\n",
            "Epoch [768/1000], Loss: 0.4682\n",
            "Epoch [770/1000], Loss: 0.4676\n",
            "Epoch [772/1000], Loss: 0.4696\n",
            "Epoch [774/1000], Loss: 0.4661\n",
            "Epoch [776/1000], Loss: 0.4704\n",
            "Epoch [778/1000], Loss: 0.4691\n",
            "Epoch [780/1000], Loss: 0.4694\n",
            "Epoch [782/1000], Loss: 0.4679\n",
            "Epoch [784/1000], Loss: 0.4702\n",
            "Epoch [786/1000], Loss: 0.4679\n",
            "Epoch [788/1000], Loss: 0.4678\n",
            "Epoch [790/1000], Loss: 0.4679\n",
            "Epoch [792/1000], Loss: 0.4688\n",
            "Epoch [794/1000], Loss: 0.4690\n",
            "Epoch [796/1000], Loss: 0.4675\n",
            "Epoch [798/1000], Loss: 0.4664\n",
            "Epoch [800/1000], Loss: 0.4718\n",
            "Epoch [802/1000], Loss: 0.4691\n",
            "Epoch [804/1000], Loss: 0.4703\n",
            "Epoch [806/1000], Loss: 0.4677\n",
            "Epoch [808/1000], Loss: 0.4684\n",
            "Epoch [810/1000], Loss: 0.4706\n",
            "Epoch [812/1000], Loss: 0.4707\n",
            "Epoch [814/1000], Loss: 0.4705\n",
            "Epoch [816/1000], Loss: 0.4658\n",
            "Epoch [818/1000], Loss: 0.4707\n",
            "Epoch [820/1000], Loss: 0.4707\n",
            "Epoch [822/1000], Loss: 0.4677\n",
            "Epoch [824/1000], Loss: 0.4674\n",
            "Epoch [826/1000], Loss: 0.4674\n",
            "Epoch [828/1000], Loss: 0.4713\n",
            "Epoch [830/1000], Loss: 0.4675\n",
            "Epoch [832/1000], Loss: 0.4681\n",
            "Epoch [834/1000], Loss: 0.4680\n",
            "Epoch [836/1000], Loss: 0.4695\n",
            "Epoch [838/1000], Loss: 0.4676\n",
            "Epoch [840/1000], Loss: 0.4693\n",
            "Epoch [842/1000], Loss: 0.4684\n",
            "Epoch [844/1000], Loss: 0.4690\n",
            "Epoch [846/1000], Loss: 0.4695\n",
            "Epoch [848/1000], Loss: 0.4664\n",
            "Epoch [850/1000], Loss: 0.4664\n",
            "Epoch [852/1000], Loss: 0.4683\n",
            "Epoch [854/1000], Loss: 0.4649\n",
            "Epoch [856/1000], Loss: 0.4691\n",
            "Epoch [858/1000], Loss: 0.4704\n",
            "Epoch [860/1000], Loss: 0.4681\n",
            "Epoch [862/1000], Loss: 0.4673\n",
            "Epoch [864/1000], Loss: 0.4696\n",
            "Epoch [866/1000], Loss: 0.4661\n",
            "Epoch [868/1000], Loss: 0.4693\n",
            "Epoch [870/1000], Loss: 0.4666\n",
            "Epoch [872/1000], Loss: 0.4687\n",
            "Epoch [874/1000], Loss: 0.4690\n",
            "Epoch [876/1000], Loss: 0.4685\n",
            "Epoch [878/1000], Loss: 0.4663\n",
            "Epoch [880/1000], Loss: 0.4685\n",
            "Epoch [882/1000], Loss: 0.4656\n",
            "Epoch [884/1000], Loss: 0.4691\n",
            "Epoch [886/1000], Loss: 0.4697\n",
            "Epoch [888/1000], Loss: 0.4684\n",
            "Epoch [890/1000], Loss: 0.4711\n",
            "Epoch [892/1000], Loss: 0.4677\n",
            "Epoch [894/1000], Loss: 0.4682\n",
            "Epoch [896/1000], Loss: 0.4719\n",
            "Epoch [898/1000], Loss: 0.4687\n",
            "Epoch [900/1000], Loss: 0.4660\n",
            "Epoch [902/1000], Loss: 0.4702\n",
            "Epoch [904/1000], Loss: 0.4681\n",
            "Epoch [906/1000], Loss: 0.4682\n",
            "Epoch [908/1000], Loss: 0.4676\n",
            "Epoch [910/1000], Loss: 0.4695\n",
            "Epoch [912/1000], Loss: 0.4653\n",
            "Epoch [914/1000], Loss: 0.4663\n",
            "Epoch [916/1000], Loss: 0.4690\n",
            "Epoch [918/1000], Loss: 0.4681\n",
            "Epoch [920/1000], Loss: 0.4682\n",
            "Epoch [922/1000], Loss: 0.4689\n",
            "Epoch [924/1000], Loss: 0.4650\n",
            "Epoch [926/1000], Loss: 0.4684\n",
            "Epoch [928/1000], Loss: 0.4694\n",
            "Epoch [930/1000], Loss: 0.4709\n",
            "Epoch [932/1000], Loss: 0.4683\n",
            "Epoch [934/1000], Loss: 0.4663\n",
            "Epoch [936/1000], Loss: 0.4685\n",
            "Epoch [938/1000], Loss: 0.4722\n",
            "Epoch [940/1000], Loss: 0.4685\n",
            "Epoch [942/1000], Loss: 0.4682\n",
            "Epoch [944/1000], Loss: 0.4678\n",
            "Epoch [946/1000], Loss: 0.4668\n",
            "Epoch [948/1000], Loss: 0.4693\n",
            "Epoch [950/1000], Loss: 0.4660\n",
            "Epoch [952/1000], Loss: 0.4662\n",
            "Epoch [954/1000], Loss: 0.4664\n",
            "Epoch [956/1000], Loss: 0.4669\n",
            "Epoch [958/1000], Loss: 0.4670\n",
            "Epoch [960/1000], Loss: 0.4673\n",
            "Epoch [962/1000], Loss: 0.4684\n",
            "Epoch [964/1000], Loss: 0.4660\n",
            "Epoch [966/1000], Loss: 0.4686\n",
            "Epoch [968/1000], Loss: 0.4664\n",
            "Epoch [970/1000], Loss: 0.4656\n",
            "Epoch [972/1000], Loss: 0.4662\n",
            "Epoch [974/1000], Loss: 0.4669\n",
            "Epoch [976/1000], Loss: 0.4702\n",
            "Epoch [978/1000], Loss: 0.4707\n",
            "Epoch [980/1000], Loss: 0.4671\n",
            "Epoch [982/1000], Loss: 0.4672\n",
            "Epoch [984/1000], Loss: 0.4657\n",
            "Epoch [986/1000], Loss: 0.4697\n",
            "Epoch [988/1000], Loss: 0.4698\n",
            "Epoch [990/1000], Loss: 0.4707\n",
            "Epoch [992/1000], Loss: 0.4650\n",
            "Epoch [994/1000], Loss: 0.4673\n",
            "Epoch [996/1000], Loss: 0.4661\n",
            "Epoch [998/1000], Loss: 0.4674\n",
            "Epoch [1000/1000], Loss: 0.4691\n",
            "Precision: 0.7226720647773279\n",
            "Recall: 0.854066985645933\n",
            "F1 Score: 0.7828947368421051\n"
          ]
        }
      ],
      "source": [
        "dev_text, dev_labels = dev_data\n",
        "train_pred, dev_pred = train_lstm_model(train_data, dev_text, ngram_counts, input_size=100, hidden_size=128, num_layers=3, output_size=1, epochs=1000, learning_rate=0.001, patience=5)\n",
        "dev_precision = get_precision(dev_labels, dev_pred)\n",
        "dev_recall = get_recall(dev_labels, dev_pred)\n",
        "dev_f = get_fscore(dev_labels, dev_pred)\n",
        "# Report the precision, recall, and f-score on the development data\n",
        "print(f\"Precision: {dev_precision}\")\n",
        "print(f\"Recall: {dev_recall}\")\n",
        "print(f\"F1 Score: {dev_f}\")"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-09-14T22:26:40.180534Z",
          "start_time": "2024-09-14T22:22:33.064937Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y9dvej84Jome",
        "outputId": "c6ef1fcc-cff0-4bf4-f8d5-899b21f849e2"
      },
      "execution_count": 116
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4.2 Analyze your model\n",
        "\n",
        "\n",
        "Describe the model and features you choose, and perform a detailed error analysis of your models. Give several examples of words on which your best model performs well. Also give examples of words which your best model performs poorly on, and identify at least TWO categories of words on which your model is making errors.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "oNCeUFiPrcoO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- **Answer 4.2**: Write a detailed description of your model and features used. Also include error analysis of your model."
      ],
      "metadata": {
        "id": "HXJgfZDyX3DW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Models Description**\n",
        "\n",
        "I implement a LSTM-based model,which is designed for sequence data classification, combining recurrent neural networks with fully connected layers for binary classification tasks.\n",
        "\n",
        "***LSTM Layer***: The core of the model is a LSTM layer, which processes sequential data and captures dependencies across time steps, making it ideal for time series or text data. The LSTM receives input in the form of sequences with dimensions [batch_size, sequence_length, input_size]. It has 128 hidden units, which allow it to learn complex patterns in the data, and it is stacked with 3 layers to increase its learning capacity.\n",
        "\n",
        "***Fully Connected Layer***: The output from the LSTM is passed through a fully connected layer, which refines the features learned by the LSTM. This layer starts with a dropout of 0.4 for regularization, helping to prevent overfitting by randomly dropping neurons during training. Following the dropout, a LeakyReLU activation function with a negative slope of 0.01 is applied, introducing non-linearity and allowing the model to avoid issues such as the vanishing gradient.\n",
        "\n",
        "***Forward Propagation***: In forward propagation, the model begins by initializing hidden states (h_0 and c_0) for the LSTM, ensuring the hidden states match the batch size. The input sequence is then passed through the LSTM, which processes the sequence step by step, producing a hidden state at each step. The output from the final time step is extracted and passed through the fully connected layers\n",
        "\n",
        "<br/>\n",
        "\n",
        "**Features Description**\n",
        "\n",
        "***Word Length***: Represents the number of characters in each word. It can capture basic structural information that helps distinguish certain classes.\n",
        "\n",
        "***Unigram Frequency***: The frequency of the word in the corpus. This feature helps capture the commonality or rarity of a word, which can be crucial in determining its class.<br/>\n",
        "\n",
        "***Syllable Count***: This feature estimates the number of syllables in a given word. The syllable count provides valuable information about the word’s phonetic complexity, which can be useful for tasks related to readability, pronunciation, or linguistic analysis.<br/>\n",
        "\n",
        "***Token Length***: This feature extracts the length of a word based on its tokenization using the BERT tokenizer. By using a pre-trained BERT model, the word is split into subword tokens, and the number of tokens is returned as a feature.<br/>\n",
        "\n",
        "***Word2Vec Embedding Mean***: This feature leverages a pre-trained Word2Vec model to generate vector embeddings for a given word. The word is converted into its vector representation, and the mean value of the vector components is used as the feature.<br/>\n",
        "\n",
        "***WordNet Synsets and Synonyms***: This feature extracts the number of senses and unique synonyms for a given word using WordNet. By counting the word's synsets (senses) and synonyms, it provides insight into the word's polysemy and lexical diversity.\n",
        "\n",
        "<br/>\n",
        "\n",
        "\n",
        "**Performance Analysis**\n",
        "The performance comparison between Naive Bayes, Logistic Regression, and the LSTM model shows that the LSTM significantly outperforms the baseline models.  Naive Bayes tends to over-predict, leading to higher recall but low precision, which limits its effectiveness.  Logistic Regression improves the balance between precision and recall, providing a more stable baseline.  However, the LSTM model, with its ability to capture complex patterns in sequential data, achieves the best overall performance, particularly excelling in its ability to minimize misclassifications, as reflected by its superior F1 score (0.783).\n",
        "\n",
        "<br/>\n",
        "\n",
        "**Error Analysis**\n",
        "\n",
        "Based on the error from output, the model tends to perform well on simple words or words that have consistent forms, such as \"go\" or \"run.\"  These words typically appear frequently and have straightforward morphology.  However, the model struggles with more complex words, particularly those with irregular forms, compound words, or those involving tense changes, such as \"gone\" or \"running.\"  Additionally, compound words or phrases like \"self-imposed\" or \"long-standing\" often lead to misclassification, as the model has difficulty understanding the nuances in how these are formed or used contextually."
      ],
      "metadata": {
        "id": "rMSVGdeTCm6D"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4.3 Leaderboard\n",
        "Finally, use your classifier to predict labels for the test data, and submit these labels in a text file named `test_labels.txt` (with one label per line) to the leaderboard; be sure NOT to shuffle the order of the test examples. Instructions for how to post to the leaderboard will be posted on Ed soon.\n",
        "**In addition, the top 3 teams will receive 5 bonus points!**"
      ],
      "metadata": {
        "id": "UyVWDdmprepx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_pred, test_pred = train_lstm_model(train_data, test_words, ngram_counts)\n",
        "test_pred = [int(pred) for sublist in test_pred for pred in sublist]\n",
        "test_pred = np.array(test_pred).flatten()\n",
        "with open('test_labels.txt', 'w') as f:\n",
        "    f.write(\"\\n\".join(map(str, test_pred)))"
      ],
      "metadata": {
        "id": "Aqh2598xqPxN",
        "ExecuteTime": {
          "end_time": "2024-09-14T22:34:11.544296Z",
          "start_time": "2024-09-14T22:27:52.944290Z"
        },
        "outputId": "f0ac8430-2648-4e60-da47-c5660485e9d5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [2/2000], Loss: 0.6996\n",
            "Epoch [4/2000], Loss: 0.6971\n",
            "Epoch [6/2000], Loss: 0.6948\n",
            "Epoch [8/2000], Loss: 0.6924\n",
            "Epoch [10/2000], Loss: 0.6899\n",
            "Epoch [12/2000], Loss: 0.6871\n",
            "Epoch [14/2000], Loss: 0.6835\n",
            "Epoch [16/2000], Loss: 0.6794\n",
            "Epoch [18/2000], Loss: 0.6743\n",
            "Epoch [20/2000], Loss: 0.6678\n",
            "Epoch [22/2000], Loss: 0.6589\n",
            "Epoch [24/2000], Loss: 0.6472\n",
            "Epoch [26/2000], Loss: 0.6338\n",
            "Epoch [28/2000], Loss: 0.6162\n",
            "Epoch [30/2000], Loss: 0.5998\n",
            "Epoch [32/2000], Loss: 0.5828\n",
            "Epoch [34/2000], Loss: 0.5700\n",
            "Epoch [36/2000], Loss: 0.5583\n",
            "Epoch [38/2000], Loss: 0.5483\n",
            "Epoch [40/2000], Loss: 0.5402\n",
            "Epoch [42/2000], Loss: 0.5308\n",
            "Epoch [44/2000], Loss: 0.5262\n",
            "Epoch [46/2000], Loss: 0.5236\n",
            "Epoch [48/2000], Loss: 0.5277\n",
            "Epoch [50/2000], Loss: 0.5265\n",
            "Epoch [52/2000], Loss: 0.5253\n",
            "Epoch [54/2000], Loss: 0.5212\n",
            "Epoch [56/2000], Loss: 0.5174\n",
            "Epoch [58/2000], Loss: 0.5165\n",
            "Epoch [60/2000], Loss: 0.5166\n",
            "Epoch [62/2000], Loss: 0.5166\n",
            "Epoch [64/2000], Loss: 0.5153\n",
            "Epoch [66/2000], Loss: 0.5148\n",
            "Epoch [68/2000], Loss: 0.5136\n",
            "Epoch [70/2000], Loss: 0.5143\n",
            "Epoch [72/2000], Loss: 0.5128\n",
            "Epoch [74/2000], Loss: 0.5127\n",
            "Epoch [76/2000], Loss: 0.5121\n",
            "Epoch [78/2000], Loss: 0.5122\n",
            "Epoch [80/2000], Loss: 0.5112\n",
            "Epoch [82/2000], Loss: 0.5128\n",
            "Epoch [84/2000], Loss: 0.5095\n",
            "Epoch [86/2000], Loss: 0.5089\n",
            "Epoch [88/2000], Loss: 0.5082\n",
            "Epoch [90/2000], Loss: 0.5096\n",
            "Epoch [92/2000], Loss: 0.5090\n",
            "Epoch [94/2000], Loss: 0.5092\n",
            "Epoch [96/2000], Loss: 0.5103\n",
            "Epoch [98/2000], Loss: 0.5071\n",
            "Epoch [100/2000], Loss: 0.5102\n",
            "Epoch [102/2000], Loss: 0.5067\n",
            "Epoch [104/2000], Loss: 0.5073\n",
            "Epoch [106/2000], Loss: 0.5074\n",
            "Epoch [108/2000], Loss: 0.5044\n",
            "Epoch [110/2000], Loss: 0.5083\n",
            "Epoch [112/2000], Loss: 0.5054\n",
            "Epoch [114/2000], Loss: 0.5062\n",
            "Epoch [116/2000], Loss: 0.5064\n",
            "Epoch [118/2000], Loss: 0.5050\n",
            "Epoch [120/2000], Loss: 0.5057\n",
            "Epoch [122/2000], Loss: 0.5047\n",
            "Epoch [124/2000], Loss: 0.5049\n",
            "Epoch [126/2000], Loss: 0.5042\n",
            "Epoch [128/2000], Loss: 0.5060\n",
            "Epoch [130/2000], Loss: 0.5043\n",
            "Epoch [132/2000], Loss: 0.5040\n",
            "Epoch [134/2000], Loss: 0.5032\n",
            "Epoch [136/2000], Loss: 0.5035\n",
            "Epoch [138/2000], Loss: 0.5038\n",
            "Epoch [140/2000], Loss: 0.5057\n",
            "Epoch [142/2000], Loss: 0.5022\n",
            "Epoch [144/2000], Loss: 0.5007\n",
            "Epoch [146/2000], Loss: 0.5034\n",
            "Epoch [148/2000], Loss: 0.5025\n",
            "Epoch [150/2000], Loss: 0.5022\n",
            "Epoch [152/2000], Loss: 0.5005\n",
            "Epoch [154/2000], Loss: 0.5014\n",
            "Epoch [156/2000], Loss: 0.5010\n",
            "Epoch [158/2000], Loss: 0.5034\n",
            "Epoch [160/2000], Loss: 0.5003\n",
            "Epoch [162/2000], Loss: 0.5031\n",
            "Epoch [164/2000], Loss: 0.5029\n",
            "Epoch [166/2000], Loss: 0.5013\n",
            "Epoch [168/2000], Loss: 0.5005\n",
            "Epoch [170/2000], Loss: 0.5008\n",
            "Epoch [172/2000], Loss: 0.5020\n",
            "Epoch [174/2000], Loss: 0.4994\n",
            "Epoch [176/2000], Loss: 0.4985\n",
            "Epoch [178/2000], Loss: 0.5013\n",
            "Epoch [180/2000], Loss: 0.4998\n",
            "Epoch [182/2000], Loss: 0.5002\n",
            "Epoch [184/2000], Loss: 0.4989\n",
            "Epoch [186/2000], Loss: 0.4970\n",
            "Epoch [188/2000], Loss: 0.4982\n",
            "Epoch [190/2000], Loss: 0.4982\n",
            "Epoch [192/2000], Loss: 0.5009\n",
            "Epoch [194/2000], Loss: 0.4951\n",
            "Epoch [196/2000], Loss: 0.4962\n",
            "Epoch [198/2000], Loss: 0.4939\n",
            "Epoch [200/2000], Loss: 0.4957\n",
            "Epoch [202/2000], Loss: 0.4959\n",
            "Epoch [204/2000], Loss: 0.4980\n",
            "Epoch [206/2000], Loss: 0.4955\n",
            "Epoch [208/2000], Loss: 0.4932\n",
            "Epoch [210/2000], Loss: 0.4962\n",
            "Epoch [212/2000], Loss: 0.4931\n",
            "Epoch [214/2000], Loss: 0.4934\n",
            "Epoch [216/2000], Loss: 0.4944\n",
            "Epoch [218/2000], Loss: 0.4937\n",
            "Epoch [220/2000], Loss: 0.4933\n",
            "Epoch [222/2000], Loss: 0.4915\n",
            "Epoch [224/2000], Loss: 0.4929\n",
            "Epoch [226/2000], Loss: 0.4940\n",
            "Epoch [228/2000], Loss: 0.4921\n",
            "Epoch [230/2000], Loss: 0.4899\n",
            "Epoch [232/2000], Loss: 0.4918\n",
            "Epoch [234/2000], Loss: 0.4894\n",
            "Epoch [236/2000], Loss: 0.4895\n",
            "Epoch [238/2000], Loss: 0.4909\n",
            "Epoch [240/2000], Loss: 0.4882\n",
            "Epoch [242/2000], Loss: 0.4882\n",
            "Epoch [244/2000], Loss: 0.4918\n",
            "Epoch [246/2000], Loss: 0.4902\n",
            "Epoch [248/2000], Loss: 0.4872\n",
            "Epoch [250/2000], Loss: 0.4877\n",
            "Epoch [252/2000], Loss: 0.4869\n",
            "Epoch [254/2000], Loss: 0.4862\n",
            "Epoch [256/2000], Loss: 0.4861\n",
            "Epoch [258/2000], Loss: 0.4867\n",
            "Epoch [260/2000], Loss: 0.4894\n",
            "Epoch [262/2000], Loss: 0.4870\n",
            "Epoch [264/2000], Loss: 0.4858\n",
            "Epoch [266/2000], Loss: 0.4862\n",
            "Epoch [268/2000], Loss: 0.4862\n",
            "Epoch [270/2000], Loss: 0.4871\n",
            "Epoch [272/2000], Loss: 0.4855\n",
            "Epoch [274/2000], Loss: 0.4853\n",
            "Epoch [276/2000], Loss: 0.4840\n",
            "Epoch [278/2000], Loss: 0.4853\n",
            "Epoch [280/2000], Loss: 0.4879\n",
            "Epoch [282/2000], Loss: 0.4844\n",
            "Epoch [284/2000], Loss: 0.4853\n",
            "Epoch [286/2000], Loss: 0.4881\n",
            "Epoch [288/2000], Loss: 0.4843\n",
            "Epoch [290/2000], Loss: 0.4834\n",
            "Epoch [292/2000], Loss: 0.4868\n",
            "Epoch [294/2000], Loss: 0.4846\n",
            "Epoch [296/2000], Loss: 0.4840\n",
            "Epoch [298/2000], Loss: 0.4840\n",
            "Epoch [300/2000], Loss: 0.4860\n",
            "Epoch [302/2000], Loss: 0.4846\n",
            "Epoch [304/2000], Loss: 0.4837\n",
            "Epoch [306/2000], Loss: 0.4845\n",
            "Epoch [308/2000], Loss: 0.4783\n",
            "Epoch [310/2000], Loss: 0.4827\n",
            "Epoch [312/2000], Loss: 0.4806\n",
            "Epoch [314/2000], Loss: 0.4828\n",
            "Epoch [316/2000], Loss: 0.4821\n",
            "Epoch [318/2000], Loss: 0.4843\n",
            "Epoch [320/2000], Loss: 0.4820\n",
            "Epoch [322/2000], Loss: 0.4799\n",
            "Epoch [324/2000], Loss: 0.4833\n",
            "Epoch [326/2000], Loss: 0.4788\n",
            "Epoch [328/2000], Loss: 0.4802\n",
            "Epoch [330/2000], Loss: 0.4810\n",
            "Epoch [332/2000], Loss: 0.4813\n",
            "Epoch [334/2000], Loss: 0.4818\n",
            "Epoch [336/2000], Loss: 0.4813\n",
            "Epoch [338/2000], Loss: 0.4812\n",
            "Epoch [340/2000], Loss: 0.4769\n",
            "Epoch [342/2000], Loss: 0.4814\n",
            "Epoch [344/2000], Loss: 0.4818\n",
            "Epoch [346/2000], Loss: 0.4790\n",
            "Epoch [348/2000], Loss: 0.4799\n",
            "Epoch [350/2000], Loss: 0.4798\n",
            "Epoch [352/2000], Loss: 0.4776\n",
            "Epoch [354/2000], Loss: 0.4786\n",
            "Epoch [356/2000], Loss: 0.4782\n",
            "Epoch [358/2000], Loss: 0.4775\n",
            "Epoch [360/2000], Loss: 0.4768\n",
            "Epoch [362/2000], Loss: 0.4789\n",
            "Epoch [364/2000], Loss: 0.4790\n",
            "Epoch [366/2000], Loss: 0.4774\n",
            "Epoch [368/2000], Loss: 0.4794\n",
            "Epoch [370/2000], Loss: 0.4780\n",
            "Epoch [372/2000], Loss: 0.4788\n",
            "Epoch [374/2000], Loss: 0.4772\n",
            "Epoch [376/2000], Loss: 0.4767\n",
            "Epoch [378/2000], Loss: 0.4808\n",
            "Epoch [380/2000], Loss: 0.4792\n",
            "Epoch [382/2000], Loss: 0.4778\n",
            "Epoch [384/2000], Loss: 0.4775\n",
            "Epoch [386/2000], Loss: 0.4767\n",
            "Epoch [388/2000], Loss: 0.4779\n",
            "Epoch [390/2000], Loss: 0.4761\n",
            "Epoch [392/2000], Loss: 0.4767\n",
            "Epoch [394/2000], Loss: 0.4779\n",
            "Epoch [396/2000], Loss: 0.4781\n",
            "Epoch [398/2000], Loss: 0.4757\n",
            "Epoch [400/2000], Loss: 0.4783\n",
            "Epoch [402/2000], Loss: 0.4792\n",
            "Epoch [404/2000], Loss: 0.4787\n",
            "Epoch [406/2000], Loss: 0.4764\n",
            "Epoch [408/2000], Loss: 0.4756\n",
            "Epoch [410/2000], Loss: 0.4754\n",
            "Epoch [412/2000], Loss: 0.4781\n",
            "Epoch [414/2000], Loss: 0.4757\n",
            "Epoch [416/2000], Loss: 0.4789\n",
            "Epoch [418/2000], Loss: 0.4756\n",
            "Epoch [420/2000], Loss: 0.4767\n",
            "Epoch [422/2000], Loss: 0.4757\n",
            "Epoch [424/2000], Loss: 0.4737\n",
            "Epoch [426/2000], Loss: 0.4792\n",
            "Epoch [428/2000], Loss: 0.4795\n",
            "Epoch [430/2000], Loss: 0.4743\n",
            "Epoch [432/2000], Loss: 0.4743\n",
            "Epoch [434/2000], Loss: 0.4776\n",
            "Epoch [436/2000], Loss: 0.4757\n",
            "Epoch [438/2000], Loss: 0.4755\n",
            "Epoch [440/2000], Loss: 0.4750\n",
            "Epoch [442/2000], Loss: 0.4771\n",
            "Epoch [444/2000], Loss: 0.4744\n",
            "Epoch [446/2000], Loss: 0.4745\n",
            "Epoch [448/2000], Loss: 0.4733\n",
            "Epoch [450/2000], Loss: 0.4740\n",
            "Epoch [452/2000], Loss: 0.4737\n",
            "Epoch [454/2000], Loss: 0.4757\n",
            "Epoch [456/2000], Loss: 0.4726\n",
            "Epoch [458/2000], Loss: 0.4769\n",
            "Epoch [460/2000], Loss: 0.4729\n",
            "Epoch [462/2000], Loss: 0.4749\n",
            "Epoch [464/2000], Loss: 0.4718\n",
            "Epoch [466/2000], Loss: 0.4721\n",
            "Epoch [468/2000], Loss: 0.4716\n",
            "Epoch [470/2000], Loss: 0.4750\n",
            "Epoch [472/2000], Loss: 0.4700\n",
            "Epoch [474/2000], Loss: 0.4721\n",
            "Epoch [476/2000], Loss: 0.4735\n",
            "Epoch [478/2000], Loss: 0.4737\n",
            "Epoch [480/2000], Loss: 0.4765\n",
            "Epoch [482/2000], Loss: 0.4743\n",
            "Epoch [484/2000], Loss: 0.4729\n",
            "Epoch [486/2000], Loss: 0.4729\n",
            "Epoch [488/2000], Loss: 0.4727\n",
            "Epoch [490/2000], Loss: 0.4721\n",
            "Epoch [492/2000], Loss: 0.4723\n",
            "Epoch [494/2000], Loss: 0.4722\n",
            "Epoch [496/2000], Loss: 0.4747\n",
            "Epoch [498/2000], Loss: 0.4732\n",
            "Epoch [500/2000], Loss: 0.4730\n",
            "Epoch [502/2000], Loss: 0.4741\n",
            "Epoch [504/2000], Loss: 0.4736\n",
            "Epoch [506/2000], Loss: 0.4726\n",
            "Epoch [508/2000], Loss: 0.4734\n",
            "Epoch [510/2000], Loss: 0.4726\n",
            "Epoch [512/2000], Loss: 0.4709\n",
            "Epoch [514/2000], Loss: 0.4721\n",
            "Epoch [516/2000], Loss: 0.4724\n",
            "Epoch [518/2000], Loss: 0.4746\n",
            "Epoch [520/2000], Loss: 0.4728\n",
            "Epoch [522/2000], Loss: 0.4742\n",
            "Epoch [524/2000], Loss: 0.4731\n",
            "Epoch [526/2000], Loss: 0.4713\n",
            "Epoch [528/2000], Loss: 0.4750\n",
            "Epoch [530/2000], Loss: 0.4703\n",
            "Epoch [532/2000], Loss: 0.4715\n",
            "Epoch [534/2000], Loss: 0.4716\n",
            "Epoch [536/2000], Loss: 0.4744\n",
            "Epoch [538/2000], Loss: 0.4741\n",
            "Epoch [540/2000], Loss: 0.4702\n",
            "Epoch [542/2000], Loss: 0.4739\n",
            "Epoch [544/2000], Loss: 0.4736\n",
            "Epoch [546/2000], Loss: 0.4733\n",
            "Epoch [548/2000], Loss: 0.4726\n",
            "Epoch [550/2000], Loss: 0.4753\n",
            "Epoch [552/2000], Loss: 0.4700\n",
            "Epoch [554/2000], Loss: 0.4705\n",
            "Epoch [556/2000], Loss: 0.4704\n",
            "Epoch [558/2000], Loss: 0.4721\n",
            "Epoch [560/2000], Loss: 0.4736\n",
            "Epoch [562/2000], Loss: 0.4709\n",
            "Epoch [564/2000], Loss: 0.4721\n",
            "Epoch [566/2000], Loss: 0.4713\n",
            "Epoch [568/2000], Loss: 0.4716\n",
            "Epoch [570/2000], Loss: 0.4735\n",
            "Epoch [572/2000], Loss: 0.4711\n",
            "Epoch [574/2000], Loss: 0.4704\n",
            "Epoch [576/2000], Loss: 0.4738\n",
            "Epoch [578/2000], Loss: 0.4733\n",
            "Epoch [580/2000], Loss: 0.4708\n",
            "Epoch [582/2000], Loss: 0.4735\n",
            "Epoch [584/2000], Loss: 0.4731\n",
            "Epoch [586/2000], Loss: 0.4688\n",
            "Epoch [588/2000], Loss: 0.4693\n",
            "Epoch [590/2000], Loss: 0.4719\n",
            "Epoch [592/2000], Loss: 0.4681\n",
            "Epoch [594/2000], Loss: 0.4727\n",
            "Epoch [596/2000], Loss: 0.4737\n",
            "Epoch [598/2000], Loss: 0.4709\n",
            "Epoch [600/2000], Loss: 0.4712\n",
            "Epoch [602/2000], Loss: 0.4718\n",
            "Epoch [604/2000], Loss: 0.4700\n",
            "Epoch [606/2000], Loss: 0.4723\n",
            "Epoch [608/2000], Loss: 0.4689\n",
            "Epoch [610/2000], Loss: 0.4709\n",
            "Epoch [612/2000], Loss: 0.4716\n",
            "Epoch [614/2000], Loss: 0.4704\n",
            "Epoch [616/2000], Loss: 0.4694\n",
            "Epoch [618/2000], Loss: 0.4689\n",
            "Epoch [620/2000], Loss: 0.4702\n",
            "Epoch [622/2000], Loss: 0.4720\n",
            "Epoch [624/2000], Loss: 0.4741\n",
            "Epoch [626/2000], Loss: 0.4712\n",
            "Epoch [628/2000], Loss: 0.4723\n",
            "Epoch [630/2000], Loss: 0.4712\n",
            "Epoch [632/2000], Loss: 0.4705\n",
            "Epoch [634/2000], Loss: 0.4727\n",
            "Epoch [636/2000], Loss: 0.4694\n",
            "Epoch [638/2000], Loss: 0.4722\n",
            "Epoch [640/2000], Loss: 0.4710\n",
            "Epoch [642/2000], Loss: 0.4731\n",
            "Epoch [644/2000], Loss: 0.4717\n",
            "Epoch [646/2000], Loss: 0.4719\n",
            "Epoch [648/2000], Loss: 0.4724\n",
            "Epoch [650/2000], Loss: 0.4692\n",
            "Epoch [652/2000], Loss: 0.4712\n",
            "Epoch [654/2000], Loss: 0.4674\n",
            "Epoch [656/2000], Loss: 0.4687\n",
            "Epoch [658/2000], Loss: 0.4727\n",
            "Epoch [660/2000], Loss: 0.4680\n",
            "Epoch [662/2000], Loss: 0.4712\n",
            "Epoch [664/2000], Loss: 0.4702\n",
            "Epoch [666/2000], Loss: 0.4686\n",
            "Epoch [668/2000], Loss: 0.4704\n",
            "Epoch [670/2000], Loss: 0.4687\n",
            "Epoch [672/2000], Loss: 0.4709\n",
            "Epoch [674/2000], Loss: 0.4704\n",
            "Epoch [676/2000], Loss: 0.4725\n",
            "Epoch [678/2000], Loss: 0.4709\n",
            "Epoch [680/2000], Loss: 0.4688\n",
            "Epoch [682/2000], Loss: 0.4708\n",
            "Epoch [684/2000], Loss: 0.4687\n",
            "Epoch [686/2000], Loss: 0.4710\n",
            "Epoch [688/2000], Loss: 0.4686\n",
            "Epoch [690/2000], Loss: 0.4709\n",
            "Epoch [692/2000], Loss: 0.4695\n",
            "Epoch [694/2000], Loss: 0.4723\n",
            "Epoch [696/2000], Loss: 0.4713\n",
            "Epoch [698/2000], Loss: 0.4713\n",
            "Epoch [700/2000], Loss: 0.4656\n",
            "Epoch [702/2000], Loss: 0.4683\n",
            "Epoch [704/2000], Loss: 0.4699\n",
            "Epoch [706/2000], Loss: 0.4692\n",
            "Epoch [708/2000], Loss: 0.4691\n",
            "Epoch [710/2000], Loss: 0.4689\n",
            "Epoch [712/2000], Loss: 0.4687\n",
            "Epoch [714/2000], Loss: 0.4705\n",
            "Epoch [716/2000], Loss: 0.4693\n",
            "Epoch [718/2000], Loss: 0.4727\n",
            "Epoch [720/2000], Loss: 0.4715\n",
            "Epoch [722/2000], Loss: 0.4695\n",
            "Epoch [724/2000], Loss: 0.4690\n",
            "Epoch [726/2000], Loss: 0.4708\n",
            "Epoch [728/2000], Loss: 0.4691\n",
            "Epoch [730/2000], Loss: 0.4711\n",
            "Epoch [732/2000], Loss: 0.4696\n",
            "Epoch [734/2000], Loss: 0.4684\n",
            "Epoch [736/2000], Loss: 0.4734\n",
            "Epoch [738/2000], Loss: 0.4702\n",
            "Epoch [740/2000], Loss: 0.4712\n",
            "Epoch [742/2000], Loss: 0.4673\n",
            "Epoch [744/2000], Loss: 0.4694\n",
            "Epoch [746/2000], Loss: 0.4684\n",
            "Epoch [748/2000], Loss: 0.4710\n",
            "Epoch [750/2000], Loss: 0.4698\n",
            "Epoch [752/2000], Loss: 0.4676\n",
            "Epoch [754/2000], Loss: 0.4714\n",
            "Epoch [756/2000], Loss: 0.4680\n",
            "Epoch [758/2000], Loss: 0.4685\n",
            "Epoch [760/2000], Loss: 0.4676\n",
            "Epoch [762/2000], Loss: 0.4706\n",
            "Epoch [764/2000], Loss: 0.4680\n",
            "Epoch [766/2000], Loss: 0.4691\n",
            "Epoch [768/2000], Loss: 0.4703\n",
            "Epoch [770/2000], Loss: 0.4743\n",
            "Epoch [772/2000], Loss: 0.4728\n",
            "Epoch [774/2000], Loss: 0.4714\n",
            "Epoch [776/2000], Loss: 0.4682\n",
            "Epoch [778/2000], Loss: 0.4708\n",
            "Epoch [780/2000], Loss: 0.4668\n",
            "Epoch [782/2000], Loss: 0.4712\n",
            "Epoch [784/2000], Loss: 0.4720\n",
            "Epoch [786/2000], Loss: 0.4704\n",
            "Epoch [788/2000], Loss: 0.4691\n",
            "Epoch [790/2000], Loss: 0.4681\n",
            "Epoch [792/2000], Loss: 0.4712\n",
            "Epoch [794/2000], Loss: 0.4696\n",
            "Epoch [796/2000], Loss: 0.4687\n",
            "Epoch [798/2000], Loss: 0.4713\n",
            "Epoch [800/2000], Loss: 0.4685\n",
            "Epoch [802/2000], Loss: 0.4682\n",
            "Epoch [804/2000], Loss: 0.4668\n",
            "Epoch [806/2000], Loss: 0.4678\n",
            "Epoch [808/2000], Loss: 0.4690\n",
            "Epoch [810/2000], Loss: 0.4667\n",
            "Epoch [812/2000], Loss: 0.4701\n",
            "Epoch [814/2000], Loss: 0.4694\n",
            "Epoch [816/2000], Loss: 0.4684\n",
            "Epoch [818/2000], Loss: 0.4697\n",
            "Epoch [820/2000], Loss: 0.4693\n",
            "Epoch [822/2000], Loss: 0.4717\n",
            "Epoch [824/2000], Loss: 0.4718\n",
            "Epoch [826/2000], Loss: 0.4693\n",
            "Epoch [828/2000], Loss: 0.4690\n",
            "Epoch [830/2000], Loss: 0.4708\n",
            "Epoch [832/2000], Loss: 0.4693\n",
            "Epoch [834/2000], Loss: 0.4692\n",
            "Epoch [836/2000], Loss: 0.4683\n",
            "Epoch [838/2000], Loss: 0.4688\n",
            "Epoch [840/2000], Loss: 0.4694\n",
            "Epoch [842/2000], Loss: 0.4670\n",
            "Epoch [844/2000], Loss: 0.4668\n",
            "Epoch [846/2000], Loss: 0.4687\n",
            "Epoch [848/2000], Loss: 0.4703\n",
            "Epoch [850/2000], Loss: 0.4667\n",
            "Epoch [852/2000], Loss: 0.4712\n",
            "Epoch [854/2000], Loss: 0.4721\n",
            "Epoch [856/2000], Loss: 0.4674\n",
            "Epoch [858/2000], Loss: 0.4668\n",
            "Epoch [860/2000], Loss: 0.4700\n",
            "Epoch [862/2000], Loss: 0.4702\n",
            "Epoch [864/2000], Loss: 0.4676\n",
            "Epoch [866/2000], Loss: 0.4683\n",
            "Epoch [868/2000], Loss: 0.4693\n",
            "Epoch [870/2000], Loss: 0.4718\n",
            "Epoch [872/2000], Loss: 0.4696\n",
            "Epoch [874/2000], Loss: 0.4664\n",
            "Epoch [876/2000], Loss: 0.4671\n",
            "Epoch [878/2000], Loss: 0.4663\n",
            "Epoch [880/2000], Loss: 0.4693\n",
            "Epoch [882/2000], Loss: 0.4695\n",
            "Epoch [884/2000], Loss: 0.4658\n",
            "Epoch [886/2000], Loss: 0.4695\n",
            "Epoch [888/2000], Loss: 0.4677\n",
            "Epoch [890/2000], Loss: 0.4713\n",
            "Epoch [892/2000], Loss: 0.4679\n",
            "Epoch [894/2000], Loss: 0.4672\n",
            "Epoch [896/2000], Loss: 0.4672\n",
            "Epoch [898/2000], Loss: 0.4676\n",
            "Epoch [900/2000], Loss: 0.4675\n",
            "Epoch [902/2000], Loss: 0.4696\n",
            "Epoch [904/2000], Loss: 0.4664\n",
            "Epoch [906/2000], Loss: 0.4694\n",
            "Epoch [908/2000], Loss: 0.4695\n",
            "Epoch [910/2000], Loss: 0.4678\n",
            "Epoch [912/2000], Loss: 0.4716\n",
            "Epoch [914/2000], Loss: 0.4642\n",
            "Epoch [916/2000], Loss: 0.4668\n",
            "Epoch [918/2000], Loss: 0.4700\n",
            "Epoch [920/2000], Loss: 0.4694\n",
            "Epoch [922/2000], Loss: 0.4683\n",
            "Epoch [924/2000], Loss: 0.4703\n",
            "Epoch [926/2000], Loss: 0.4690\n",
            "Epoch [928/2000], Loss: 0.4662\n",
            "Epoch [930/2000], Loss: 0.4675\n",
            "Epoch [932/2000], Loss: 0.4681\n",
            "Epoch [934/2000], Loss: 0.4655\n",
            "Epoch [936/2000], Loss: 0.4713\n",
            "Epoch [938/2000], Loss: 0.4684\n",
            "Epoch [940/2000], Loss: 0.4683\n",
            "Epoch [942/2000], Loss: 0.4680\n",
            "Epoch [944/2000], Loss: 0.4701\n",
            "Epoch [946/2000], Loss: 0.4729\n",
            "Epoch [948/2000], Loss: 0.4650\n",
            "Epoch [950/2000], Loss: 0.4680\n",
            "Epoch [952/2000], Loss: 0.4689\n",
            "Epoch [954/2000], Loss: 0.4701\n",
            "Epoch [956/2000], Loss: 0.4728\n",
            "Epoch [958/2000], Loss: 0.4665\n",
            "Epoch [960/2000], Loss: 0.4692\n",
            "Epoch [962/2000], Loss: 0.4652\n",
            "Epoch [964/2000], Loss: 0.4660\n",
            "Epoch [966/2000], Loss: 0.4675\n",
            "Epoch [968/2000], Loss: 0.4666\n",
            "Epoch [970/2000], Loss: 0.4677\n",
            "Epoch [972/2000], Loss: 0.4684\n",
            "Epoch [974/2000], Loss: 0.4678\n",
            "Epoch [976/2000], Loss: 0.4695\n",
            "Epoch [978/2000], Loss: 0.4683\n",
            "Epoch [980/2000], Loss: 0.4643\n",
            "Epoch [982/2000], Loss: 0.4687\n",
            "Epoch [984/2000], Loss: 0.4678\n",
            "Epoch [986/2000], Loss: 0.4684\n",
            "Epoch [988/2000], Loss: 0.4656\n",
            "Epoch [990/2000], Loss: 0.4676\n",
            "Epoch [992/2000], Loss: 0.4677\n",
            "Epoch [994/2000], Loss: 0.4677\n",
            "Epoch [996/2000], Loss: 0.4659\n",
            "Epoch [998/2000], Loss: 0.4627\n",
            "Epoch [1000/2000], Loss: 0.4651\n",
            "Epoch [1002/2000], Loss: 0.4683\n",
            "Epoch [1004/2000], Loss: 0.4673\n",
            "Epoch [1006/2000], Loss: 0.4668\n",
            "Epoch [1008/2000], Loss: 0.4680\n",
            "Epoch [1010/2000], Loss: 0.4679\n",
            "Epoch [1012/2000], Loss: 0.4665\n",
            "Epoch [1014/2000], Loss: 0.4701\n",
            "Epoch [1016/2000], Loss: 0.4671\n",
            "Epoch [1018/2000], Loss: 0.4702\n",
            "Epoch [1020/2000], Loss: 0.4673\n",
            "Epoch [1022/2000], Loss: 0.4663\n",
            "Epoch [1024/2000], Loss: 0.4687\n",
            "Epoch [1026/2000], Loss: 0.4692\n",
            "Epoch [1028/2000], Loss: 0.4674\n",
            "Epoch [1030/2000], Loss: 0.4694\n",
            "Epoch [1032/2000], Loss: 0.4680\n",
            "Epoch [1034/2000], Loss: 0.4699\n",
            "Epoch [1036/2000], Loss: 0.4659\n",
            "Epoch [1038/2000], Loss: 0.4674\n",
            "Epoch [1040/2000], Loss: 0.4675\n",
            "Epoch [1042/2000], Loss: 0.4657\n",
            "Epoch [1044/2000], Loss: 0.4670\n",
            "Epoch [1046/2000], Loss: 0.4636\n",
            "Epoch [1048/2000], Loss: 0.4687\n",
            "Epoch [1050/2000], Loss: 0.4707\n",
            "Epoch [1052/2000], Loss: 0.4683\n",
            "Epoch [1054/2000], Loss: 0.4688\n",
            "Epoch [1056/2000], Loss: 0.4705\n",
            "Epoch [1058/2000], Loss: 0.4695\n",
            "Epoch [1060/2000], Loss: 0.4672\n",
            "Epoch [1062/2000], Loss: 0.4674\n",
            "Epoch [1064/2000], Loss: 0.4681\n",
            "Epoch [1066/2000], Loss: 0.4673\n",
            "Epoch [1068/2000], Loss: 0.4675\n",
            "Epoch [1070/2000], Loss: 0.4661\n",
            "Epoch [1072/2000], Loss: 0.4671\n",
            "Epoch [1074/2000], Loss: 0.4680\n",
            "Epoch [1076/2000], Loss: 0.4673\n",
            "Epoch [1078/2000], Loss: 0.4654\n",
            "Epoch [1080/2000], Loss: 0.4648\n",
            "Epoch [1082/2000], Loss: 0.4670\n",
            "Epoch [1084/2000], Loss: 0.4682\n",
            "Epoch [1086/2000], Loss: 0.4642\n",
            "Epoch [1088/2000], Loss: 0.4681\n",
            "Epoch [1090/2000], Loss: 0.4654\n",
            "Epoch [1092/2000], Loss: 0.4647\n",
            "Epoch [1094/2000], Loss: 0.4660\n",
            "Epoch [1096/2000], Loss: 0.4680\n",
            "Epoch [1098/2000], Loss: 0.4680\n",
            "Epoch [1100/2000], Loss: 0.4666\n",
            "Epoch [1102/2000], Loss: 0.4689\n",
            "Epoch [1104/2000], Loss: 0.4664\n",
            "Epoch [1106/2000], Loss: 0.4665\n",
            "Epoch [1108/2000], Loss: 0.4681\n",
            "Epoch [1110/2000], Loss: 0.4675\n",
            "Epoch [1112/2000], Loss: 0.4659\n",
            "Epoch [1114/2000], Loss: 0.4672\n",
            "Epoch [1116/2000], Loss: 0.4670\n",
            "Epoch [1118/2000], Loss: 0.4639\n",
            "Epoch [1120/2000], Loss: 0.4692\n",
            "Epoch [1122/2000], Loss: 0.4660\n",
            "Epoch [1124/2000], Loss: 0.4656\n",
            "Epoch [1126/2000], Loss: 0.4672\n",
            "Epoch [1128/2000], Loss: 0.4685\n",
            "Epoch [1130/2000], Loss: 0.4648\n",
            "Epoch [1132/2000], Loss: 0.4670\n",
            "Epoch [1134/2000], Loss: 0.4647\n",
            "Epoch [1136/2000], Loss: 0.4668\n",
            "Epoch [1138/2000], Loss: 0.4672\n",
            "Epoch [1140/2000], Loss: 0.4670\n",
            "Epoch [1142/2000], Loss: 0.4663\n",
            "Epoch [1144/2000], Loss: 0.4660\n",
            "Epoch [1146/2000], Loss: 0.4648\n",
            "Epoch [1148/2000], Loss: 0.4660\n",
            "Epoch [1150/2000], Loss: 0.4643\n",
            "Epoch [1152/2000], Loss: 0.4678\n",
            "Epoch [1154/2000], Loss: 0.4652\n",
            "Epoch [1156/2000], Loss: 0.4719\n",
            "Epoch [1158/2000], Loss: 0.4683\n",
            "Epoch [1160/2000], Loss: 0.4683\n",
            "Epoch [1162/2000], Loss: 0.4663\n",
            "Epoch [1164/2000], Loss: 0.4659\n",
            "Epoch [1166/2000], Loss: 0.4660\n",
            "Epoch [1168/2000], Loss: 0.4658\n",
            "Epoch [1170/2000], Loss: 0.4647\n",
            "Epoch [1172/2000], Loss: 0.4646\n",
            "Epoch [1174/2000], Loss: 0.4673\n",
            "Epoch [1176/2000], Loss: 0.4648\n",
            "Epoch [1178/2000], Loss: 0.4677\n",
            "Epoch [1180/2000], Loss: 0.4681\n",
            "Epoch [1182/2000], Loss: 0.4675\n",
            "Epoch [1184/2000], Loss: 0.4662\n",
            "Epoch [1186/2000], Loss: 0.4666\n",
            "Epoch [1188/2000], Loss: 0.4643\n",
            "Epoch [1190/2000], Loss: 0.4658\n",
            "Epoch [1192/2000], Loss: 0.4678\n",
            "Epoch [1194/2000], Loss: 0.4662\n",
            "Epoch [1196/2000], Loss: 0.4654\n",
            "Epoch [1198/2000], Loss: 0.4663\n",
            "Epoch [1200/2000], Loss: 0.4641\n",
            "Epoch [1202/2000], Loss: 0.4668\n",
            "Epoch [1204/2000], Loss: 0.4658\n",
            "Epoch [1206/2000], Loss: 0.4672\n",
            "Epoch [1208/2000], Loss: 0.4650\n",
            "Epoch [1210/2000], Loss: 0.4680\n",
            "Epoch [1212/2000], Loss: 0.4642\n",
            "Epoch [1214/2000], Loss: 0.4664\n",
            "Epoch [1216/2000], Loss: 0.4679\n",
            "Epoch [1218/2000], Loss: 0.4637\n",
            "Epoch [1220/2000], Loss: 0.4674\n",
            "Epoch [1222/2000], Loss: 0.4676\n",
            "Epoch [1224/2000], Loss: 0.4674\n",
            "Epoch [1226/2000], Loss: 0.4662\n",
            "Epoch [1228/2000], Loss: 0.4645\n",
            "Epoch [1230/2000], Loss: 0.4653\n",
            "Epoch [1232/2000], Loss: 0.4665\n",
            "Epoch [1234/2000], Loss: 0.4680\n",
            "Epoch [1236/2000], Loss: 0.4649\n",
            "Epoch [1238/2000], Loss: 0.4647\n",
            "Epoch [1240/2000], Loss: 0.4632\n",
            "Epoch [1242/2000], Loss: 0.4656\n",
            "Epoch [1244/2000], Loss: 0.4604\n",
            "Epoch [1246/2000], Loss: 0.4645\n",
            "Epoch [1248/2000], Loss: 0.4658\n",
            "Epoch [1250/2000], Loss: 0.4663\n",
            "Epoch [1252/2000], Loss: 0.4670\n",
            "Epoch [1254/2000], Loss: 0.4651\n",
            "Epoch [1256/2000], Loss: 0.4661\n",
            "Epoch [1258/2000], Loss: 0.4664\n",
            "Epoch [1260/2000], Loss: 0.4652\n",
            "Epoch [1262/2000], Loss: 0.4651\n",
            "Epoch [1264/2000], Loss: 0.4644\n",
            "Epoch [1266/2000], Loss: 0.4634\n",
            "Epoch [1268/2000], Loss: 0.4658\n",
            "Epoch [1270/2000], Loss: 0.4633\n",
            "Epoch [1272/2000], Loss: 0.4681\n",
            "Epoch [1274/2000], Loss: 0.4671\n",
            "Epoch [1276/2000], Loss: 0.4676\n",
            "Epoch [1278/2000], Loss: 0.4624\n",
            "Epoch [1280/2000], Loss: 0.4674\n",
            "Epoch [1282/2000], Loss: 0.4649\n",
            "Epoch [1284/2000], Loss: 0.4655\n",
            "Epoch [1286/2000], Loss: 0.4656\n",
            "Epoch [1288/2000], Loss: 0.4631\n",
            "Epoch [1290/2000], Loss: 0.4650\n",
            "Epoch [1292/2000], Loss: 0.4660\n",
            "Epoch [1294/2000], Loss: 0.4650\n",
            "Epoch [1296/2000], Loss: 0.4673\n",
            "Epoch [1298/2000], Loss: 0.4662\n",
            "Epoch [1300/2000], Loss: 0.4637\n",
            "Epoch [1302/2000], Loss: 0.4648\n",
            "Epoch [1304/2000], Loss: 0.4650\n",
            "Epoch [1306/2000], Loss: 0.4652\n",
            "Epoch [1308/2000], Loss: 0.4642\n",
            "Epoch [1310/2000], Loss: 0.4637\n",
            "Epoch [1312/2000], Loss: 0.4657\n",
            "Epoch [1314/2000], Loss: 0.4644\n",
            "Epoch [1316/2000], Loss: 0.4654\n",
            "Epoch [1318/2000], Loss: 0.4633\n",
            "Epoch [1320/2000], Loss: 0.4611\n",
            "Epoch [1322/2000], Loss: 0.4644\n",
            "Epoch [1324/2000], Loss: 0.4636\n",
            "Epoch [1326/2000], Loss: 0.4663\n",
            "Epoch [1328/2000], Loss: 0.4652\n",
            "Epoch [1330/2000], Loss: 0.4651\n",
            "Epoch [1332/2000], Loss: 0.4672\n",
            "Epoch [1334/2000], Loss: 0.4663\n",
            "Epoch [1336/2000], Loss: 0.4638\n",
            "Epoch [1338/2000], Loss: 0.4648\n",
            "Epoch [1340/2000], Loss: 0.4678\n",
            "Epoch [1342/2000], Loss: 0.4664\n",
            "Epoch [1344/2000], Loss: 0.4675\n",
            "Epoch [1346/2000], Loss: 0.4658\n",
            "Epoch [1348/2000], Loss: 0.4658\n",
            "Epoch [1350/2000], Loss: 0.4663\n",
            "Epoch [1352/2000], Loss: 0.4660\n",
            "Epoch [1354/2000], Loss: 0.4634\n",
            "Epoch [1356/2000], Loss: 0.4644\n",
            "Epoch [1358/2000], Loss: 0.4643\n",
            "Epoch [1360/2000], Loss: 0.4639\n",
            "Epoch [1362/2000], Loss: 0.4665\n",
            "Epoch [1364/2000], Loss: 0.4645\n",
            "Epoch [1366/2000], Loss: 0.4671\n",
            "Epoch [1368/2000], Loss: 0.4638\n",
            "Epoch [1370/2000], Loss: 0.4636\n",
            "Epoch [1372/2000], Loss: 0.4635\n",
            "Epoch [1374/2000], Loss: 0.4642\n",
            "Epoch [1376/2000], Loss: 0.4630\n",
            "Epoch [1378/2000], Loss: 0.4648\n",
            "Epoch [1380/2000], Loss: 0.4633\n",
            "Epoch [1382/2000], Loss: 0.4659\n",
            "Epoch [1384/2000], Loss: 0.4647\n",
            "Epoch [1386/2000], Loss: 0.4652\n",
            "Epoch [1388/2000], Loss: 0.4638\n",
            "Epoch [1390/2000], Loss: 0.4623\n",
            "Epoch [1392/2000], Loss: 0.4640\n",
            "Epoch [1394/2000], Loss: 0.4662\n",
            "Epoch [1396/2000], Loss: 0.4655\n",
            "Epoch [1398/2000], Loss: 0.4648\n",
            "Epoch [1400/2000], Loss: 0.4651\n",
            "Epoch [1402/2000], Loss: 0.4616\n",
            "Epoch [1404/2000], Loss: 0.4639\n",
            "Epoch [1406/2000], Loss: 0.4646\n",
            "Epoch [1408/2000], Loss: 0.4666\n",
            "Epoch [1410/2000], Loss: 0.4618\n",
            "Epoch [1412/2000], Loss: 0.4659\n",
            "Epoch [1414/2000], Loss: 0.4643\n",
            "Epoch [1416/2000], Loss: 0.4618\n",
            "Epoch [1418/2000], Loss: 0.4624\n",
            "Epoch [1420/2000], Loss: 0.4631\n",
            "Epoch [1422/2000], Loss: 0.4660\n",
            "Epoch [1424/2000], Loss: 0.4622\n",
            "Epoch [1426/2000], Loss: 0.4601\n",
            "Epoch [1428/2000], Loss: 0.4650\n",
            "Epoch [1430/2000], Loss: 0.4629\n",
            "Epoch [1432/2000], Loss: 0.4651\n",
            "Epoch [1434/2000], Loss: 0.4596\n",
            "Epoch [1436/2000], Loss: 0.4649\n",
            "Epoch [1438/2000], Loss: 0.4668\n",
            "Epoch [1440/2000], Loss: 0.4650\n",
            "Epoch [1442/2000], Loss: 0.4633\n",
            "Epoch [1444/2000], Loss: 0.4647\n",
            "Epoch [1446/2000], Loss: 0.4651\n",
            "Epoch [1448/2000], Loss: 0.4666\n",
            "Epoch [1450/2000], Loss: 0.4630\n",
            "Epoch [1452/2000], Loss: 0.4645\n",
            "Epoch [1454/2000], Loss: 0.4623\n",
            "Epoch [1456/2000], Loss: 0.4647\n",
            "Epoch [1458/2000], Loss: 0.4656\n",
            "Epoch [1460/2000], Loss: 0.4641\n",
            "Epoch [1462/2000], Loss: 0.4583\n",
            "Epoch [1464/2000], Loss: 0.4656\n",
            "Epoch [1466/2000], Loss: 0.4655\n",
            "Epoch [1468/2000], Loss: 0.4666\n",
            "Epoch [1470/2000], Loss: 0.4638\n",
            "Epoch [1472/2000], Loss: 0.4654\n",
            "Epoch [1474/2000], Loss: 0.4640\n",
            "Epoch [1476/2000], Loss: 0.4665\n",
            "Epoch [1478/2000], Loss: 0.4632\n",
            "Epoch [1480/2000], Loss: 0.4652\n",
            "Epoch [1482/2000], Loss: 0.4630\n",
            "Epoch [1484/2000], Loss: 0.4645\n",
            "Epoch [1486/2000], Loss: 0.4609\n",
            "Epoch [1488/2000], Loss: 0.4659\n",
            "Epoch [1490/2000], Loss: 0.4642\n",
            "Epoch [1492/2000], Loss: 0.4661\n",
            "Epoch [1494/2000], Loss: 0.4629\n",
            "Epoch [1496/2000], Loss: 0.4625\n",
            "Epoch [1498/2000], Loss: 0.4644\n",
            "Epoch [1500/2000], Loss: 0.4626\n",
            "Epoch [1502/2000], Loss: 0.4629\n",
            "Epoch [1504/2000], Loss: 0.4644\n",
            "Epoch [1506/2000], Loss: 0.4640\n",
            "Epoch [1508/2000], Loss: 0.4641\n",
            "Epoch [1510/2000], Loss: 0.4632\n",
            "Epoch [1512/2000], Loss: 0.4663\n",
            "Epoch [1514/2000], Loss: 0.4643\n",
            "Epoch [1516/2000], Loss: 0.4636\n",
            "Epoch [1518/2000], Loss: 0.4648\n",
            "Epoch [1520/2000], Loss: 0.4615\n",
            "Epoch [1522/2000], Loss: 0.4629\n",
            "Epoch [1524/2000], Loss: 0.4656\n",
            "Epoch [1526/2000], Loss: 0.4641\n",
            "Epoch [1528/2000], Loss: 0.4679\n",
            "Epoch [1530/2000], Loss: 0.4651\n",
            "Epoch [1532/2000], Loss: 0.4665\n",
            "Epoch [1534/2000], Loss: 0.4603\n",
            "Epoch [1536/2000], Loss: 0.4633\n",
            "Epoch [1538/2000], Loss: 0.4620\n",
            "Epoch [1540/2000], Loss: 0.4626\n",
            "Epoch [1542/2000], Loss: 0.4655\n",
            "Epoch [1544/2000], Loss: 0.4607\n",
            "Epoch [1546/2000], Loss: 0.4653\n",
            "Epoch [1548/2000], Loss: 0.4629\n",
            "Epoch [1550/2000], Loss: 0.4643\n",
            "Epoch [1552/2000], Loss: 0.4667\n",
            "Epoch [1554/2000], Loss: 0.4650\n",
            "Epoch [1556/2000], Loss: 0.4623\n",
            "Epoch [1558/2000], Loss: 0.4633\n",
            "Epoch [1560/2000], Loss: 0.4646\n",
            "Epoch [1562/2000], Loss: 0.4649\n",
            "Epoch [1564/2000], Loss: 0.4631\n",
            "Epoch [1566/2000], Loss: 0.4658\n",
            "Epoch [1568/2000], Loss: 0.4614\n",
            "Epoch [1570/2000], Loss: 0.4638\n",
            "Epoch [1572/2000], Loss: 0.4627\n",
            "Epoch [1574/2000], Loss: 0.4612\n",
            "Epoch [1576/2000], Loss: 0.4642\n",
            "Epoch [1578/2000], Loss: 0.4606\n",
            "Epoch [1580/2000], Loss: 0.4594\n",
            "Epoch [1582/2000], Loss: 0.4606\n",
            "Epoch [1584/2000], Loss: 0.4658\n",
            "Epoch [1586/2000], Loss: 0.4623\n",
            "Epoch [1588/2000], Loss: 0.4664\n",
            "Epoch [1590/2000], Loss: 0.4634\n",
            "Epoch [1592/2000], Loss: 0.4626\n",
            "Epoch [1594/2000], Loss: 0.4651\n",
            "Epoch [1596/2000], Loss: 0.4600\n",
            "Epoch [1598/2000], Loss: 0.4630\n",
            "Epoch [1600/2000], Loss: 0.4639\n",
            "Epoch [1602/2000], Loss: 0.4640\n",
            "Epoch [1604/2000], Loss: 0.4612\n",
            "Epoch [1606/2000], Loss: 0.4635\n",
            "Epoch [1608/2000], Loss: 0.4615\n",
            "Epoch [1610/2000], Loss: 0.4630\n",
            "Epoch [1612/2000], Loss: 0.4613\n",
            "Epoch [1614/2000], Loss: 0.4640\n",
            "Epoch [1616/2000], Loss: 0.4594\n",
            "Epoch [1618/2000], Loss: 0.4649\n",
            "Epoch [1620/2000], Loss: 0.4656\n",
            "Epoch [1622/2000], Loss: 0.4612\n",
            "Epoch [1624/2000], Loss: 0.4656\n",
            "Epoch [1626/2000], Loss: 0.4625\n",
            "Epoch [1628/2000], Loss: 0.4593\n",
            "Epoch [1630/2000], Loss: 0.4610\n",
            "Epoch [1632/2000], Loss: 0.4635\n",
            "Epoch [1634/2000], Loss: 0.4639\n",
            "Epoch [1636/2000], Loss: 0.4627\n",
            "Epoch [1638/2000], Loss: 0.4648\n",
            "Epoch [1640/2000], Loss: 0.4619\n",
            "Epoch [1642/2000], Loss: 0.4615\n",
            "Epoch [1644/2000], Loss: 0.4615\n",
            "Epoch [1646/2000], Loss: 0.4653\n",
            "Epoch [1648/2000], Loss: 0.4632\n",
            "Epoch [1650/2000], Loss: 0.4610\n",
            "Epoch [1652/2000], Loss: 0.4629\n",
            "Epoch [1654/2000], Loss: 0.4654\n",
            "Epoch [1656/2000], Loss: 0.4609\n",
            "Epoch [1658/2000], Loss: 0.4598\n",
            "Epoch [1660/2000], Loss: 0.4629\n",
            "Epoch [1662/2000], Loss: 0.4625\n",
            "Epoch [1664/2000], Loss: 0.4628\n",
            "Epoch [1666/2000], Loss: 0.4661\n",
            "Epoch [1668/2000], Loss: 0.4639\n",
            "Epoch [1670/2000], Loss: 0.4627\n",
            "Epoch [1672/2000], Loss: 0.4636\n",
            "Epoch [1674/2000], Loss: 0.4656\n",
            "Epoch [1676/2000], Loss: 0.4617\n",
            "Epoch [1678/2000], Loss: 0.4648\n",
            "Epoch [1680/2000], Loss: 0.4639\n",
            "Epoch [1682/2000], Loss: 0.4629\n",
            "Epoch [1684/2000], Loss: 0.4625\n",
            "Epoch [1686/2000], Loss: 0.4624\n",
            "Epoch [1688/2000], Loss: 0.4648\n",
            "Epoch [1690/2000], Loss: 0.4665\n",
            "Epoch [1692/2000], Loss: 0.4622\n",
            "Epoch [1694/2000], Loss: 0.4634\n",
            "Epoch [1696/2000], Loss: 0.4638\n",
            "Epoch [1698/2000], Loss: 0.4620\n",
            "Epoch [1700/2000], Loss: 0.4637\n",
            "Epoch [1702/2000], Loss: 0.4618\n",
            "Epoch [1704/2000], Loss: 0.4636\n",
            "Epoch [1706/2000], Loss: 0.4627\n",
            "Epoch [1708/2000], Loss: 0.4653\n",
            "Epoch [1710/2000], Loss: 0.4626\n",
            "Epoch [1712/2000], Loss: 0.4620\n",
            "Epoch [1714/2000], Loss: 0.4590\n",
            "Epoch [1716/2000], Loss: 0.4624\n",
            "Epoch [1718/2000], Loss: 0.4628\n",
            "Epoch [1720/2000], Loss: 0.4609\n",
            "Epoch [1722/2000], Loss: 0.4617\n",
            "Epoch [1724/2000], Loss: 0.4616\n",
            "Epoch [1726/2000], Loss: 0.4625\n",
            "Epoch [1728/2000], Loss: 0.4627\n",
            "Epoch [1730/2000], Loss: 0.4631\n",
            "Epoch [1732/2000], Loss: 0.4605\n",
            "Epoch [1734/2000], Loss: 0.4645\n",
            "Epoch [1736/2000], Loss: 0.4589\n",
            "Epoch [1738/2000], Loss: 0.4605\n",
            "Epoch [1740/2000], Loss: 0.4652\n",
            "Epoch [1742/2000], Loss: 0.4632\n",
            "Epoch [1744/2000], Loss: 0.4610\n",
            "Epoch [1746/2000], Loss: 0.4649\n",
            "Epoch [1748/2000], Loss: 0.4636\n",
            "Epoch [1750/2000], Loss: 0.4635\n",
            "Epoch [1752/2000], Loss: 0.4615\n",
            "Epoch [1754/2000], Loss: 0.4595\n",
            "Epoch [1756/2000], Loss: 0.4586\n",
            "Epoch [1758/2000], Loss: 0.4595\n",
            "Epoch [1760/2000], Loss: 0.4642\n",
            "Epoch [1762/2000], Loss: 0.4606\n",
            "Epoch [1764/2000], Loss: 0.4601\n",
            "Epoch [1766/2000], Loss: 0.4582\n",
            "Epoch [1768/2000], Loss: 0.4608\n",
            "Epoch [1770/2000], Loss: 0.4571\n",
            "Epoch [1772/2000], Loss: 0.4612\n",
            "Epoch [1774/2000], Loss: 0.4618\n",
            "Epoch [1776/2000], Loss: 0.4605\n",
            "Epoch [1778/2000], Loss: 0.4614\n",
            "Epoch [1780/2000], Loss: 0.4611\n",
            "Epoch [1782/2000], Loss: 0.4611\n",
            "Epoch [1784/2000], Loss: 0.4583\n",
            "Epoch [1786/2000], Loss: 0.4594\n",
            "Epoch [1788/2000], Loss: 0.4631\n",
            "Epoch [1790/2000], Loss: 0.4619\n",
            "Epoch [1792/2000], Loss: 0.4607\n",
            "Epoch [1794/2000], Loss: 0.4607\n",
            "Epoch [1796/2000], Loss: 0.4605\n",
            "Epoch [1798/2000], Loss: 0.4609\n",
            "Epoch [1800/2000], Loss: 0.4600\n",
            "Epoch [1802/2000], Loss: 0.4618\n",
            "Epoch [1804/2000], Loss: 0.4659\n",
            "Epoch [1806/2000], Loss: 0.4613\n",
            "Epoch [1808/2000], Loss: 0.4605\n",
            "Epoch [1810/2000], Loss: 0.4607\n",
            "Epoch [1812/2000], Loss: 0.4634\n",
            "Epoch [1814/2000], Loss: 0.4620\n",
            "Epoch [1816/2000], Loss: 0.4602\n",
            "Epoch [1818/2000], Loss: 0.4654\n",
            "Epoch [1820/2000], Loss: 0.4601\n",
            "Epoch [1822/2000], Loss: 0.4606\n",
            "Epoch [1824/2000], Loss: 0.4602\n",
            "Epoch [1826/2000], Loss: 0.4630\n",
            "Epoch [1828/2000], Loss: 0.4613\n",
            "Epoch [1830/2000], Loss: 0.4617\n",
            "Epoch [1832/2000], Loss: 0.4611\n",
            "Epoch [1834/2000], Loss: 0.4619\n",
            "Epoch [1836/2000], Loss: 0.4590\n",
            "Epoch [1838/2000], Loss: 0.4599\n",
            "Epoch [1840/2000], Loss: 0.4619\n",
            "Epoch [1842/2000], Loss: 0.4615\n",
            "Epoch [1844/2000], Loss: 0.4620\n",
            "Epoch [1846/2000], Loss: 0.4605\n",
            "Epoch [1848/2000], Loss: 0.4585\n",
            "Epoch [1850/2000], Loss: 0.4615\n",
            "Epoch [1852/2000], Loss: 0.4639\n",
            "Epoch [1854/2000], Loss: 0.4636\n",
            "Epoch [1856/2000], Loss: 0.4628\n",
            "Epoch [1858/2000], Loss: 0.4615\n",
            "Epoch [1860/2000], Loss: 0.4601\n",
            "Epoch [1862/2000], Loss: 0.4607\n",
            "Epoch [1864/2000], Loss: 0.4604\n",
            "Epoch [1866/2000], Loss: 0.4598\n",
            "Epoch [1868/2000], Loss: 0.4594\n",
            "Epoch [1870/2000], Loss: 0.4609\n",
            "Epoch [1872/2000], Loss: 0.4608\n",
            "Epoch [1874/2000], Loss: 0.4629\n",
            "Epoch [1876/2000], Loss: 0.4601\n",
            "Epoch [1878/2000], Loss: 0.4581\n",
            "Epoch [1880/2000], Loss: 0.4616\n",
            "Epoch [1882/2000], Loss: 0.4598\n",
            "Epoch [1884/2000], Loss: 0.4598\n",
            "Epoch [1886/2000], Loss: 0.4611\n",
            "Epoch [1888/2000], Loss: 0.4629\n",
            "Epoch [1890/2000], Loss: 0.4594\n",
            "Epoch [1892/2000], Loss: 0.4592\n",
            "Epoch [1894/2000], Loss: 0.4615\n",
            "Epoch [1896/2000], Loss: 0.4603\n",
            "Epoch [1898/2000], Loss: 0.4627\n",
            "Epoch [1900/2000], Loss: 0.4619\n",
            "Epoch [1902/2000], Loss: 0.4632\n",
            "Epoch [1904/2000], Loss: 0.4566\n",
            "Epoch [1906/2000], Loss: 0.4609\n",
            "Epoch [1908/2000], Loss: 0.4599\n",
            "Epoch [1910/2000], Loss: 0.4614\n",
            "Epoch [1912/2000], Loss: 0.4639\n",
            "Epoch [1914/2000], Loss: 0.4609\n",
            "Epoch [1916/2000], Loss: 0.4612\n",
            "Epoch [1918/2000], Loss: 0.4632\n",
            "Epoch [1920/2000], Loss: 0.4609\n",
            "Epoch [1922/2000], Loss: 0.4559\n",
            "Epoch [1924/2000], Loss: 0.4633\n",
            "Epoch [1926/2000], Loss: 0.4608\n",
            "Epoch [1928/2000], Loss: 0.4623\n",
            "Epoch [1930/2000], Loss: 0.4591\n",
            "Epoch [1932/2000], Loss: 0.4605\n",
            "Epoch [1934/2000], Loss: 0.4619\n",
            "Epoch [1936/2000], Loss: 0.4583\n",
            "Epoch [1938/2000], Loss: 0.4610\n",
            "Epoch [1940/2000], Loss: 0.4598\n",
            "Epoch [1942/2000], Loss: 0.4606\n",
            "Epoch [1944/2000], Loss: 0.4575\n",
            "Epoch [1946/2000], Loss: 0.4590\n",
            "Epoch [1948/2000], Loss: 0.4589\n",
            "Epoch [1950/2000], Loss: 0.4607\n",
            "Epoch [1952/2000], Loss: 0.4611\n",
            "Epoch [1954/2000], Loss: 0.4616\n",
            "Epoch [1956/2000], Loss: 0.4615\n",
            "Epoch [1958/2000], Loss: 0.4594\n",
            "Epoch [1960/2000], Loss: 0.4626\n",
            "Epoch [1962/2000], Loss: 0.4594\n",
            "Epoch [1964/2000], Loss: 0.4610\n",
            "Epoch [1966/2000], Loss: 0.4619\n",
            "Epoch [1968/2000], Loss: 0.4621\n",
            "Epoch [1970/2000], Loss: 0.4582\n",
            "Epoch [1972/2000], Loss: 0.4615\n",
            "Epoch [1974/2000], Loss: 0.4613\n",
            "Epoch [1976/2000], Loss: 0.4601\n",
            "Epoch [1978/2000], Loss: 0.4595\n",
            "Epoch [1980/2000], Loss: 0.4607\n",
            "Epoch [1982/2000], Loss: 0.4619\n",
            "Epoch [1984/2000], Loss: 0.4600\n",
            "Epoch [1986/2000], Loss: 0.4615\n",
            "Epoch [1988/2000], Loss: 0.4628\n",
            "Epoch [1990/2000], Loss: 0.4592\n",
            "Epoch [1992/2000], Loss: 0.4590\n",
            "Epoch [1994/2000], Loss: 0.4585\n",
            "Epoch [1996/2000], Loss: 0.4605\n",
            "Epoch [1998/2000], Loss: 0.4599\n",
            "Epoch [2000/2000], Loss: 0.4592\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- **Answer 4.3**: Upload your `test_labels.txt` to the leaderboard in Gradescope."
      ],
      "metadata": {
        "id": "K5F0dXt8YiGq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4.4. (Optional) Leaderboard using outside data\n",
        "\n",
        "While the training data we have provided is sufficient for completing this assignment, it is not the only data for the task of identifying complex words. As an optional addition to this homework, you may look for and use any additional training data, and submit your predicted labels in a text file named `test_labels.txt` to the leaderboard.\n",
        "\n",
        "As a start, we recommend looking at the [SemEval 2016 dataset](http://alt.qcri.org/semeval2016/task11/), a dataset that was used in a complex words identification competition. In addition, you can try to use data from [Newsela](https://newsela.com/). Newsela’s editors re-write newspaper articles to be appropriate for students at different grade levels. The company has generously shared a dataset with us. The Newsela data **may not** be re-distributed outside of Penn. You can find the data on eniac at `/home1/c/ccb/data/newsela/newsela_article_corpus_with_scripts_2016-01-29.1.zip`.\n",
        "\n",
        "Good luck, and have fun!"
      ],
      "metadata": {
        "id": "fIaGDgYzrhL_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Submission\n",
        "Here are the deliverables that you will need to submit:\n",
        "- This notebook (rename them to `homework1.ipynb` and `homework1.py`)\n",
        "- Your model’s output for the test set using only the provided training and development data (`test_labels.txt`)\n",
        "- (Optional) your model’s output for the test set, using any data that you want. (`test_labels.txt`)"
      ],
      "metadata": {
        "id": "zve_zJnFrkgy"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "OzwLD_nSmANT"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}